{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T07:56:12.339418Z",
     "start_time": "2025-05-25T07:56:12.323750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque"
   ],
   "id": "d77a2f781a9383a6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:01:20.066763Z",
     "start_time": "2025-05-25T08:00:35.245968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "gamma = 0.99\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.01\n",
    "epsilon_decay = 500\n",
    "batch_size = 64\n",
    "buffer_limit = 10000\n",
    "min_buffer = 1000\n",
    "target_update_freq = 10\n",
    "episodes = 500\n",
    "\n",
    "# Q-network\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Replay buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self):\n",
    "        self.buffer = deque(maxlen=buffer_limit)\n",
    "\n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "\n",
    "    def sample(self):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        s, a, r, s_prime, done = zip(*batch)\n",
    "        return (\n",
    "            torch.tensor(s, dtype=torch.float),\n",
    "            torch.tensor(a),\n",
    "            torch.tensor(r),\n",
    "            torch.tensor(s_prime, dtype=torch.float),\n",
    "            torch.tensor(done, dtype=torch.float)\n",
    "        )\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# Epsilon-greedy policy\n",
    "def epsilon_greedy(q_net, state, epsilon):\n",
    "    if random.random() < epsilon:\n",
    "        return random.randint(0, 1)\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            state = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "            q_values = q_net(state)\n",
    "            return q_values.argmax().item()\n",
    "\n",
    "# Main training loop\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "q_net = QNet()\n",
    "target_net = QNet()\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=learning_rate)\n",
    "memory = ReplayBuffer()\n",
    "\n",
    "def train(q_net, target_net, memory, optimizer):\n",
    "    s, a, r, s_prime, done = memory.sample()\n",
    "\n",
    "    q_out = q_net(s)\n",
    "    q_a = q_out.gather(1, a.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        max_q_prime = target_net(s_prime).max(1)[0]\n",
    "        target = r + gamma * max_q_prime * (1 - done)\n",
    "\n",
    "    loss = nn.MSELoss()(q_a, target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()[0]\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    epsilon = epsilon_end + (epsilon_start - epsilon_end) * np.exp(-1. * episode / epsilon_decay)\n",
    "\n",
    "    while not done:\n",
    "        action = epsilon_greedy(q_net, state, epsilon)\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        memory.put((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if memory.size() >= min_buffer:\n",
    "            train(q_net, target_net, memory, optimizer)\n",
    "\n",
    "    if episode % target_update_freq == 0:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    print(f\"Episode {episode+1}, Reward: {total_reward:.2f}, Epsilon: {epsilon:.3f}\")\n",
    "\n",
    "env.close()"
   ],
   "id": "c12fc5b245e8481c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Reward: 49.00, Epsilon: 1.000\n",
      "Episode 2, Reward: 27.00, Epsilon: 0.998\n",
      "Episode 3, Reward: 15.00, Epsilon: 0.996\n",
      "Episode 4, Reward: 16.00, Epsilon: 0.994\n",
      "Episode 5, Reward: 22.00, Epsilon: 0.992\n",
      "Episode 6, Reward: 22.00, Epsilon: 0.990\n",
      "Episode 7, Reward: 20.00, Epsilon: 0.988\n",
      "Episode 8, Reward: 10.00, Epsilon: 0.986\n",
      "Episode 9, Reward: 12.00, Epsilon: 0.984\n",
      "Episode 10, Reward: 53.00, Epsilon: 0.982\n",
      "Episode 11, Reward: 30.00, Epsilon: 0.980\n",
      "Episode 12, Reward: 15.00, Epsilon: 0.978\n",
      "Episode 13, Reward: 13.00, Epsilon: 0.977\n",
      "Episode 14, Reward: 31.00, Epsilon: 0.975\n",
      "Episode 15, Reward: 19.00, Epsilon: 0.973\n",
      "Episode 16, Reward: 19.00, Epsilon: 0.971\n",
      "Episode 17, Reward: 37.00, Epsilon: 0.969\n",
      "Episode 18, Reward: 50.00, Epsilon: 0.967\n",
      "Episode 19, Reward: 12.00, Epsilon: 0.965\n",
      "Episode 20, Reward: 22.00, Epsilon: 0.963\n",
      "Episode 21, Reward: 21.00, Epsilon: 0.961\n",
      "Episode 22, Reward: 15.00, Epsilon: 0.959\n",
      "Episode 23, Reward: 14.00, Epsilon: 0.957\n",
      "Episode 24, Reward: 13.00, Epsilon: 0.955\n",
      "Episode 25, Reward: 42.00, Epsilon: 0.954\n",
      "Episode 26, Reward: 50.00, Epsilon: 0.952\n",
      "Episode 27, Reward: 14.00, Epsilon: 0.950\n",
      "Episode 28, Reward: 17.00, Epsilon: 0.948\n",
      "Episode 29, Reward: 11.00, Epsilon: 0.946\n",
      "Episode 30, Reward: 25.00, Epsilon: 0.944\n",
      "Episode 31, Reward: 15.00, Epsilon: 0.942\n",
      "Episode 32, Reward: 27.00, Epsilon: 0.940\n",
      "Episode 33, Reward: 29.00, Epsilon: 0.939\n",
      "Episode 34, Reward: 18.00, Epsilon: 0.937\n",
      "Episode 35, Reward: 16.00, Epsilon: 0.935\n",
      "Episode 36, Reward: 60.00, Epsilon: 0.933\n",
      "Episode 37, Reward: 12.00, Epsilon: 0.931\n",
      "Episode 38, Reward: 14.00, Epsilon: 0.929\n",
      "Episode 39, Reward: 14.00, Epsilon: 0.928\n",
      "Episode 40, Reward: 27.00, Epsilon: 0.926\n",
      "Episode 41, Reward: 11.00, Epsilon: 0.924\n",
      "Episode 42, Reward: 31.00, Epsilon: 0.922\n",
      "Episode 43, Reward: 15.00, Epsilon: 0.920\n",
      "Episode 44, Reward: 17.00, Epsilon: 0.918\n",
      "Episode 45, Reward: 11.00, Epsilon: 0.917\n",
      "Episode 46, Reward: 12.00, Epsilon: 0.915\n",
      "Episode 47, Reward: 19.00, Epsilon: 0.913\n",
      "Episode 48, Reward: 25.00, Epsilon: 0.911\n",
      "Episode 49, Reward: 20.00, Epsilon: 0.909\n",
      "Episode 50, Reward: 17.00, Epsilon: 0.908\n",
      "Episode 51, Reward: 41.00, Epsilon: 0.906\n",
      "Episode 52, Reward: 10.00, Epsilon: 0.904\n",
      "Episode 53, Reward: 25.00, Epsilon: 0.902\n",
      "Episode 54, Reward: 16.00, Epsilon: 0.900\n",
      "Episode 55, Reward: 16.00, Epsilon: 0.899\n",
      "Episode 56, Reward: 10.00, Epsilon: 0.897\n",
      "Episode 57, Reward: 30.00, Epsilon: 0.895\n",
      "Episode 58, Reward: 14.00, Epsilon: 0.893\n",
      "Episode 59, Reward: 16.00, Epsilon: 0.892\n",
      "Episode 60, Reward: 14.00, Epsilon: 0.890\n",
      "Episode 61, Reward: 17.00, Epsilon: 0.888\n",
      "Episode 62, Reward: 17.00, Epsilon: 0.886\n",
      "Episode 63, Reward: 10.00, Epsilon: 0.885\n",
      "Episode 64, Reward: 14.00, Epsilon: 0.883\n",
      "Episode 65, Reward: 35.00, Epsilon: 0.881\n",
      "Episode 66, Reward: 11.00, Epsilon: 0.879\n",
      "Episode 67, Reward: 20.00, Epsilon: 0.878\n",
      "Episode 68, Reward: 15.00, Epsilon: 0.876\n",
      "Episode 69, Reward: 17.00, Epsilon: 0.874\n",
      "Episode 70, Reward: 54.00, Epsilon: 0.872\n",
      "Episode 71, Reward: 15.00, Epsilon: 0.871\n",
      "Episode 72, Reward: 17.00, Epsilon: 0.869\n",
      "Episode 73, Reward: 21.00, Epsilon: 0.867\n",
      "Episode 74, Reward: 10.00, Epsilon: 0.866\n",
      "Episode 75, Reward: 16.00, Epsilon: 0.864\n",
      "Episode 76, Reward: 37.00, Epsilon: 0.862\n",
      "Episode 77, Reward: 56.00, Epsilon: 0.860\n",
      "Episode 78, Reward: 15.00, Epsilon: 0.859\n",
      "Episode 79, Reward: 30.00, Epsilon: 0.857\n",
      "Episode 80, Reward: 11.00, Epsilon: 0.855\n",
      "Episode 81, Reward: 39.00, Epsilon: 0.854\n",
      "Episode 82, Reward: 44.00, Epsilon: 0.852\n",
      "Episode 83, Reward: 20.00, Epsilon: 0.850\n",
      "Episode 84, Reward: 38.00, Epsilon: 0.849\n",
      "Episode 85, Reward: 42.00, Epsilon: 0.847\n",
      "Episode 86, Reward: 32.00, Epsilon: 0.845\n",
      "Episode 87, Reward: 60.00, Epsilon: 0.844\n",
      "Episode 88, Reward: 12.00, Epsilon: 0.842\n",
      "Episode 89, Reward: 92.00, Epsilon: 0.840\n",
      "Episode 90, Reward: 17.00, Epsilon: 0.839\n",
      "Episode 91, Reward: 57.00, Epsilon: 0.837\n",
      "Episode 92, Reward: 51.00, Epsilon: 0.835\n",
      "Episode 93, Reward: 27.00, Epsilon: 0.834\n",
      "Episode 94, Reward: 54.00, Epsilon: 0.832\n",
      "Episode 95, Reward: 12.00, Epsilon: 0.830\n",
      "Episode 96, Reward: 71.00, Epsilon: 0.829\n",
      "Episode 97, Reward: 23.00, Epsilon: 0.827\n",
      "Episode 98, Reward: 50.00, Epsilon: 0.825\n",
      "Episode 99, Reward: 29.00, Epsilon: 0.824\n",
      "Episode 100, Reward: 16.00, Epsilon: 0.822\n",
      "Episode 101, Reward: 38.00, Epsilon: 0.821\n",
      "Episode 102, Reward: 22.00, Epsilon: 0.819\n",
      "Episode 103, Reward: 66.00, Epsilon: 0.817\n",
      "Episode 104, Reward: 11.00, Epsilon: 0.816\n",
      "Episode 105, Reward: 29.00, Epsilon: 0.814\n",
      "Episode 106, Reward: 46.00, Epsilon: 0.812\n",
      "Episode 107, Reward: 17.00, Epsilon: 0.811\n",
      "Episode 108, Reward: 12.00, Epsilon: 0.809\n",
      "Episode 109, Reward: 31.00, Epsilon: 0.808\n",
      "Episode 110, Reward: 55.00, Epsilon: 0.806\n",
      "Episode 111, Reward: 12.00, Epsilon: 0.804\n",
      "Episode 112, Reward: 31.00, Epsilon: 0.803\n",
      "Episode 113, Reward: 30.00, Epsilon: 0.801\n",
      "Episode 114, Reward: 55.00, Epsilon: 0.800\n",
      "Episode 115, Reward: 59.00, Epsilon: 0.798\n",
      "Episode 116, Reward: 58.00, Epsilon: 0.797\n",
      "Episode 117, Reward: 19.00, Epsilon: 0.795\n",
      "Episode 118, Reward: 33.00, Epsilon: 0.793\n",
      "Episode 119, Reward: 29.00, Epsilon: 0.792\n",
      "Episode 120, Reward: 15.00, Epsilon: 0.790\n",
      "Episode 121, Reward: 16.00, Epsilon: 0.789\n",
      "Episode 122, Reward: 13.00, Epsilon: 0.787\n",
      "Episode 123, Reward: 10.00, Epsilon: 0.786\n",
      "Episode 124, Reward: 37.00, Epsilon: 0.784\n",
      "Episode 125, Reward: 136.00, Epsilon: 0.783\n",
      "Episode 126, Reward: 46.00, Epsilon: 0.781\n",
      "Episode 127, Reward: 74.00, Epsilon: 0.779\n",
      "Episode 128, Reward: 184.00, Epsilon: 0.778\n",
      "Episode 129, Reward: 47.00, Epsilon: 0.776\n",
      "Episode 130, Reward: 19.00, Epsilon: 0.775\n",
      "Episode 131, Reward: 56.00, Epsilon: 0.773\n",
      "Episode 132, Reward: 20.00, Epsilon: 0.772\n",
      "Episode 133, Reward: 28.00, Epsilon: 0.770\n",
      "Episode 134, Reward: 34.00, Epsilon: 0.769\n",
      "Episode 135, Reward: 43.00, Epsilon: 0.767\n",
      "Episode 136, Reward: 20.00, Epsilon: 0.766\n",
      "Episode 137, Reward: 18.00, Epsilon: 0.764\n",
      "Episode 138, Reward: 54.00, Epsilon: 0.763\n",
      "Episode 139, Reward: 20.00, Epsilon: 0.761\n",
      "Episode 140, Reward: 12.00, Epsilon: 0.760\n",
      "Episode 141, Reward: 16.00, Epsilon: 0.758\n",
      "Episode 142, Reward: 22.00, Epsilon: 0.757\n",
      "Episode 143, Reward: 109.00, Epsilon: 0.755\n",
      "Episode 144, Reward: 42.00, Epsilon: 0.754\n",
      "Episode 145, Reward: 28.00, Epsilon: 0.752\n",
      "Episode 146, Reward: 46.00, Epsilon: 0.751\n",
      "Episode 147, Reward: 42.00, Epsilon: 0.749\n",
      "Episode 148, Reward: 23.00, Epsilon: 0.748\n",
      "Episode 149, Reward: 21.00, Epsilon: 0.746\n",
      "Episode 150, Reward: 24.00, Epsilon: 0.745\n",
      "Episode 151, Reward: 29.00, Epsilon: 0.743\n",
      "Episode 152, Reward: 24.00, Epsilon: 0.742\n",
      "Episode 153, Reward: 55.00, Epsilon: 0.740\n",
      "Episode 154, Reward: 94.00, Epsilon: 0.739\n",
      "Episode 155, Reward: 66.00, Epsilon: 0.738\n",
      "Episode 156, Reward: 39.00, Epsilon: 0.736\n",
      "Episode 157, Reward: 35.00, Epsilon: 0.735\n",
      "Episode 158, Reward: 16.00, Epsilon: 0.733\n",
      "Episode 159, Reward: 76.00, Epsilon: 0.732\n",
      "Episode 160, Reward: 23.00, Epsilon: 0.730\n",
      "Episode 161, Reward: 18.00, Epsilon: 0.729\n",
      "Episode 162, Reward: 30.00, Epsilon: 0.727\n",
      "Episode 163, Reward: 40.00, Epsilon: 0.726\n",
      "Episode 164, Reward: 27.00, Epsilon: 0.725\n",
      "Episode 165, Reward: 14.00, Epsilon: 0.723\n",
      "Episode 166, Reward: 11.00, Epsilon: 0.722\n",
      "Episode 167, Reward: 32.00, Epsilon: 0.720\n",
      "Episode 168, Reward: 35.00, Epsilon: 0.719\n",
      "Episode 169, Reward: 28.00, Epsilon: 0.717\n",
      "Episode 170, Reward: 15.00, Epsilon: 0.716\n",
      "Episode 171, Reward: 82.00, Epsilon: 0.715\n",
      "Episode 172, Reward: 25.00, Epsilon: 0.713\n",
      "Episode 173, Reward: 28.00, Epsilon: 0.712\n",
      "Episode 174, Reward: 39.00, Epsilon: 0.710\n",
      "Episode 175, Reward: 92.00, Epsilon: 0.709\n",
      "Episode 176, Reward: 121.00, Epsilon: 0.708\n",
      "Episode 177, Reward: 130.00, Epsilon: 0.706\n",
      "Episode 178, Reward: 35.00, Epsilon: 0.705\n",
      "Episode 179, Reward: 66.00, Epsilon: 0.703\n",
      "Episode 180, Reward: 24.00, Epsilon: 0.702\n",
      "Episode 181, Reward: 48.00, Epsilon: 0.701\n",
      "Episode 182, Reward: 16.00, Epsilon: 0.699\n",
      "Episode 183, Reward: 51.00, Epsilon: 0.698\n",
      "Episode 184, Reward: 157.00, Epsilon: 0.697\n",
      "Episode 185, Reward: 78.00, Epsilon: 0.695\n",
      "Episode 186, Reward: 82.00, Epsilon: 0.694\n",
      "Episode 187, Reward: 35.00, Epsilon: 0.692\n",
      "Episode 188, Reward: 30.00, Epsilon: 0.691\n",
      "Episode 189, Reward: 67.00, Epsilon: 0.690\n",
      "Episode 190, Reward: 44.00, Epsilon: 0.688\n",
      "Episode 191, Reward: 66.00, Epsilon: 0.687\n",
      "Episode 192, Reward: 24.00, Epsilon: 0.686\n",
      "Episode 193, Reward: 12.00, Epsilon: 0.684\n",
      "Episode 194, Reward: 17.00, Epsilon: 0.683\n",
      "Episode 195, Reward: 18.00, Epsilon: 0.682\n",
      "Episode 196, Reward: 58.00, Epsilon: 0.680\n",
      "Episode 197, Reward: 120.00, Epsilon: 0.679\n",
      "Episode 198, Reward: 19.00, Epsilon: 0.678\n",
      "Episode 199, Reward: 68.00, Epsilon: 0.676\n",
      "Episode 200, Reward: 23.00, Epsilon: 0.675\n",
      "Episode 201, Reward: 20.00, Epsilon: 0.674\n",
      "Episode 202, Reward: 189.00, Epsilon: 0.672\n",
      "Episode 203, Reward: 21.00, Epsilon: 0.671\n",
      "Episode 204, Reward: 83.00, Epsilon: 0.670\n",
      "Episode 205, Reward: 97.00, Epsilon: 0.668\n",
      "Episode 206, Reward: 118.00, Epsilon: 0.667\n",
      "Episode 207, Reward: 79.00, Epsilon: 0.666\n",
      "Episode 208, Reward: 63.00, Epsilon: 0.664\n",
      "Episode 209, Reward: 31.00, Epsilon: 0.663\n",
      "Episode 210, Reward: 17.00, Epsilon: 0.662\n",
      "Episode 211, Reward: 85.00, Epsilon: 0.660\n",
      "Episode 212, Reward: 48.00, Epsilon: 0.659\n",
      "Episode 213, Reward: 13.00, Epsilon: 0.658\n",
      "Episode 214, Reward: 36.00, Epsilon: 0.657\n",
      "Episode 215, Reward: 120.00, Epsilon: 0.655\n",
      "Episode 216, Reward: 34.00, Epsilon: 0.654\n",
      "Episode 217, Reward: 39.00, Epsilon: 0.653\n",
      "Episode 218, Reward: 74.00, Epsilon: 0.651\n",
      "Episode 219, Reward: 58.00, Epsilon: 0.650\n",
      "Episode 220, Reward: 121.00, Epsilon: 0.649\n",
      "Episode 221, Reward: 99.00, Epsilon: 0.648\n",
      "Episode 222, Reward: 35.00, Epsilon: 0.646\n",
      "Episode 223, Reward: 31.00, Epsilon: 0.645\n",
      "Episode 224, Reward: 60.00, Epsilon: 0.644\n",
      "Episode 225, Reward: 47.00, Epsilon: 0.643\n",
      "Episode 226, Reward: 27.00, Epsilon: 0.641\n",
      "Episode 227, Reward: 102.00, Epsilon: 0.640\n",
      "Episode 228, Reward: 104.00, Epsilon: 0.639\n",
      "Episode 229, Reward: 47.00, Epsilon: 0.637\n",
      "Episode 230, Reward: 74.00, Epsilon: 0.636\n",
      "Episode 231, Reward: 50.00, Epsilon: 0.635\n",
      "Episode 232, Reward: 189.00, Epsilon: 0.634\n",
      "Episode 233, Reward: 14.00, Epsilon: 0.632\n",
      "Episode 234, Reward: 78.00, Epsilon: 0.631\n",
      "Episode 235, Reward: 33.00, Epsilon: 0.630\n",
      "Episode 236, Reward: 19.00, Epsilon: 0.629\n",
      "Episode 237, Reward: 93.00, Epsilon: 0.628\n",
      "Episode 238, Reward: 17.00, Epsilon: 0.626\n",
      "Episode 239, Reward: 16.00, Epsilon: 0.625\n",
      "Episode 240, Reward: 11.00, Epsilon: 0.624\n",
      "Episode 241, Reward: 147.00, Epsilon: 0.623\n",
      "Episode 242, Reward: 11.00, Epsilon: 0.621\n",
      "Episode 243, Reward: 27.00, Epsilon: 0.620\n",
      "Episode 244, Reward: 86.00, Epsilon: 0.619\n",
      "Episode 245, Reward: 77.00, Epsilon: 0.618\n",
      "Episode 246, Reward: 122.00, Epsilon: 0.617\n",
      "Episode 247, Reward: 25.00, Epsilon: 0.615\n",
      "Episode 248, Reward: 160.00, Epsilon: 0.614\n",
      "Episode 249, Reward: 90.00, Epsilon: 0.613\n",
      "Episode 250, Reward: 13.00, Epsilon: 0.612\n",
      "Episode 251, Reward: 17.00, Epsilon: 0.610\n",
      "Episode 252, Reward: 125.00, Epsilon: 0.609\n",
      "Episode 253, Reward: 76.00, Epsilon: 0.608\n",
      "Episode 254, Reward: 30.00, Epsilon: 0.607\n",
      "Episode 255, Reward: 47.00, Epsilon: 0.606\n",
      "Episode 256, Reward: 105.00, Epsilon: 0.604\n",
      "Episode 257, Reward: 72.00, Epsilon: 0.603\n",
      "Episode 258, Reward: 39.00, Epsilon: 0.602\n",
      "Episode 259, Reward: 70.00, Epsilon: 0.601\n",
      "Episode 260, Reward: 66.00, Epsilon: 0.600\n",
      "Episode 261, Reward: 173.00, Epsilon: 0.599\n",
      "Episode 262, Reward: 79.00, Epsilon: 0.597\n",
      "Episode 263, Reward: 77.00, Epsilon: 0.596\n",
      "Episode 264, Reward: 98.00, Epsilon: 0.595\n",
      "Episode 265, Reward: 17.00, Epsilon: 0.594\n",
      "Episode 266, Reward: 105.00, Epsilon: 0.593\n",
      "Episode 267, Reward: 220.00, Epsilon: 0.592\n",
      "Episode 268, Reward: 42.00, Epsilon: 0.590\n",
      "Episode 269, Reward: 39.00, Epsilon: 0.589\n",
      "Episode 270, Reward: 145.00, Epsilon: 0.588\n",
      "Episode 271, Reward: 22.00, Epsilon: 0.587\n",
      "Episode 272, Reward: 72.00, Epsilon: 0.586\n",
      "Episode 273, Reward: 82.00, Epsilon: 0.585\n",
      "Episode 274, Reward: 80.00, Epsilon: 0.583\n",
      "Episode 275, Reward: 121.00, Epsilon: 0.582\n",
      "Episode 276, Reward: 34.00, Epsilon: 0.581\n",
      "Episode 277, Reward: 83.00, Epsilon: 0.580\n",
      "Episode 278, Reward: 45.00, Epsilon: 0.579\n",
      "Episode 279, Reward: 80.00, Epsilon: 0.578\n",
      "Episode 280, Reward: 94.00, Epsilon: 0.577\n",
      "Episode 281, Reward: 26.00, Epsilon: 0.575\n",
      "Episode 282, Reward: 65.00, Epsilon: 0.574\n",
      "Episode 283, Reward: 88.00, Epsilon: 0.573\n",
      "Episode 284, Reward: 80.00, Epsilon: 0.572\n",
      "Episode 285, Reward: 200.00, Epsilon: 0.571\n",
      "Episode 286, Reward: 33.00, Epsilon: 0.570\n",
      "Episode 287, Reward: 29.00, Epsilon: 0.569\n",
      "Episode 288, Reward: 52.00, Epsilon: 0.568\n",
      "Episode 289, Reward: 20.00, Epsilon: 0.567\n",
      "Episode 290, Reward: 25.00, Epsilon: 0.565\n",
      "Episode 291, Reward: 25.00, Epsilon: 0.564\n",
      "Episode 292, Reward: 73.00, Epsilon: 0.563\n",
      "Episode 293, Reward: 48.00, Epsilon: 0.562\n",
      "Episode 294, Reward: 72.00, Epsilon: 0.561\n",
      "Episode 295, Reward: 71.00, Epsilon: 0.560\n",
      "Episode 296, Reward: 227.00, Epsilon: 0.559\n",
      "Episode 297, Reward: 81.00, Epsilon: 0.558\n",
      "Episode 298, Reward: 24.00, Epsilon: 0.557\n",
      "Episode 299, Reward: 40.00, Epsilon: 0.556\n",
      "Episode 300, Reward: 67.00, Epsilon: 0.554\n",
      "Episode 301, Reward: 241.00, Epsilon: 0.553\n",
      "Episode 302, Reward: 71.00, Epsilon: 0.552\n",
      "Episode 303, Reward: 23.00, Epsilon: 0.551\n",
      "Episode 304, Reward: 160.00, Epsilon: 0.550\n",
      "Episode 305, Reward: 31.00, Epsilon: 0.549\n",
      "Episode 306, Reward: 39.00, Epsilon: 0.548\n",
      "Episode 307, Reward: 25.00, Epsilon: 0.547\n",
      "Episode 308, Reward: 25.00, Epsilon: 0.546\n",
      "Episode 309, Reward: 91.00, Epsilon: 0.545\n",
      "Episode 310, Reward: 124.00, Epsilon: 0.544\n",
      "Episode 311, Reward: 84.00, Epsilon: 0.543\n",
      "Episode 312, Reward: 190.00, Epsilon: 0.542\n",
      "Episode 313, Reward: 118.00, Epsilon: 0.540\n",
      "Episode 314, Reward: 42.00, Epsilon: 0.539\n",
      "Episode 315, Reward: 97.00, Epsilon: 0.538\n",
      "Episode 316, Reward: 32.00, Epsilon: 0.537\n",
      "Episode 317, Reward: 48.00, Epsilon: 0.536\n",
      "Episode 318, Reward: 37.00, Epsilon: 0.535\n",
      "Episode 319, Reward: 13.00, Epsilon: 0.534\n",
      "Episode 320, Reward: 107.00, Epsilon: 0.533\n",
      "Episode 321, Reward: 13.00, Epsilon: 0.532\n",
      "Episode 322, Reward: 111.00, Epsilon: 0.531\n",
      "Episode 323, Reward: 183.00, Epsilon: 0.530\n",
      "Episode 324, Reward: 84.00, Epsilon: 0.529\n",
      "Episode 325, Reward: 130.00, Epsilon: 0.528\n",
      "Episode 326, Reward: 183.00, Epsilon: 0.527\n",
      "Episode 327, Reward: 37.00, Epsilon: 0.526\n",
      "Episode 328, Reward: 44.00, Epsilon: 0.525\n",
      "Episode 329, Reward: 94.00, Epsilon: 0.524\n",
      "Episode 330, Reward: 42.00, Epsilon: 0.523\n",
      "Episode 331, Reward: 71.00, Epsilon: 0.522\n",
      "Episode 332, Reward: 63.00, Epsilon: 0.521\n",
      "Episode 333, Reward: 179.00, Epsilon: 0.520\n",
      "Episode 334, Reward: 94.00, Epsilon: 0.519\n",
      "Episode 335, Reward: 23.00, Epsilon: 0.518\n",
      "Episode 336, Reward: 34.00, Epsilon: 0.517\n",
      "Episode 337, Reward: 14.00, Epsilon: 0.516\n",
      "Episode 338, Reward: 43.00, Epsilon: 0.515\n",
      "Episode 339, Reward: 171.00, Epsilon: 0.514\n",
      "Episode 340, Reward: 128.00, Epsilon: 0.513\n",
      "Episode 341, Reward: 17.00, Epsilon: 0.512\n",
      "Episode 342, Reward: 51.00, Epsilon: 0.511\n",
      "Episode 343, Reward: 16.00, Epsilon: 0.510\n",
      "Episode 344, Reward: 181.00, Epsilon: 0.509\n",
      "Episode 345, Reward: 28.00, Epsilon: 0.508\n",
      "Episode 346, Reward: 93.00, Epsilon: 0.507\n",
      "Episode 347, Reward: 218.00, Epsilon: 0.506\n",
      "Episode 348, Reward: 79.00, Epsilon: 0.505\n",
      "Episode 349, Reward: 84.00, Epsilon: 0.504\n",
      "Episode 350, Reward: 117.00, Epsilon: 0.503\n",
      "Episode 351, Reward: 127.00, Epsilon: 0.502\n",
      "Episode 352, Reward: 182.00, Epsilon: 0.501\n",
      "Episode 353, Reward: 57.00, Epsilon: 0.500\n",
      "Episode 354, Reward: 194.00, Epsilon: 0.499\n",
      "Episode 355, Reward: 27.00, Epsilon: 0.498\n",
      "Episode 356, Reward: 208.00, Epsilon: 0.497\n",
      "Episode 357, Reward: 81.00, Epsilon: 0.496\n",
      "Episode 358, Reward: 87.00, Epsilon: 0.495\n",
      "Episode 359, Reward: 83.00, Epsilon: 0.494\n",
      "Episode 360, Reward: 66.00, Epsilon: 0.493\n",
      "Episode 361, Reward: 176.00, Epsilon: 0.492\n",
      "Episode 362, Reward: 247.00, Epsilon: 0.491\n",
      "Episode 363, Reward: 151.00, Epsilon: 0.490\n",
      "Episode 364, Reward: 27.00, Epsilon: 0.489\n",
      "Episode 365, Reward: 157.00, Epsilon: 0.488\n",
      "Episode 366, Reward: 165.00, Epsilon: 0.487\n",
      "Episode 367, Reward: 20.00, Epsilon: 0.486\n",
      "Episode 368, Reward: 17.00, Epsilon: 0.485\n",
      "Episode 369, Reward: 223.00, Epsilon: 0.484\n",
      "Episode 370, Reward: 32.00, Epsilon: 0.483\n",
      "Episode 371, Reward: 169.00, Epsilon: 0.482\n",
      "Episode 372, Reward: 178.00, Epsilon: 0.481\n",
      "Episode 373, Reward: 40.00, Epsilon: 0.480\n",
      "Episode 374, Reward: 143.00, Epsilon: 0.480\n",
      "Episode 375, Reward: 217.00, Epsilon: 0.479\n",
      "Episode 376, Reward: 184.00, Epsilon: 0.478\n",
      "Episode 377, Reward: 82.00, Epsilon: 0.477\n",
      "Episode 378, Reward: 110.00, Epsilon: 0.476\n",
      "Episode 379, Reward: 71.00, Epsilon: 0.475\n",
      "Episode 380, Reward: 91.00, Epsilon: 0.474\n",
      "Episode 381, Reward: 37.00, Epsilon: 0.473\n",
      "Episode 382, Reward: 206.00, Epsilon: 0.472\n",
      "Episode 383, Reward: 11.00, Epsilon: 0.471\n",
      "Episode 384, Reward: 40.00, Epsilon: 0.470\n",
      "Episode 385, Reward: 86.00, Epsilon: 0.469\n",
      "Episode 386, Reward: 31.00, Epsilon: 0.468\n",
      "Episode 387, Reward: 72.00, Epsilon: 0.467\n",
      "Episode 388, Reward: 152.00, Epsilon: 0.467\n",
      "Episode 389, Reward: 92.00, Epsilon: 0.466\n",
      "Episode 390, Reward: 30.00, Epsilon: 0.465\n",
      "Episode 391, Reward: 75.00, Epsilon: 0.464\n",
      "Episode 392, Reward: 78.00, Epsilon: 0.463\n",
      "Episode 393, Reward: 133.00, Epsilon: 0.462\n",
      "Episode 394, Reward: 127.00, Epsilon: 0.461\n",
      "Episode 395, Reward: 123.00, Epsilon: 0.460\n",
      "Episode 396, Reward: 138.00, Epsilon: 0.459\n",
      "Episode 397, Reward: 262.00, Epsilon: 0.458\n",
      "Episode 398, Reward: 36.00, Epsilon: 0.458\n",
      "Episode 399, Reward: 43.00, Epsilon: 0.457\n",
      "Episode 400, Reward: 48.00, Epsilon: 0.456\n",
      "Episode 401, Reward: 72.00, Epsilon: 0.455\n",
      "Episode 402, Reward: 103.00, Epsilon: 0.454\n",
      "Episode 403, Reward: 249.00, Epsilon: 0.453\n",
      "Episode 404, Reward: 265.00, Epsilon: 0.452\n",
      "Episode 405, Reward: 17.00, Epsilon: 0.451\n",
      "Episode 406, Reward: 217.00, Epsilon: 0.450\n",
      "Episode 407, Reward: 203.00, Epsilon: 0.450\n",
      "Episode 408, Reward: 15.00, Epsilon: 0.449\n",
      "Episode 409, Reward: 163.00, Epsilon: 0.448\n",
      "Episode 410, Reward: 225.00, Epsilon: 0.447\n",
      "Episode 411, Reward: 151.00, Epsilon: 0.446\n",
      "Episode 412, Reward: 222.00, Epsilon: 0.445\n",
      "Episode 413, Reward: 82.00, Epsilon: 0.444\n",
      "Episode 414, Reward: 11.00, Epsilon: 0.443\n",
      "Episode 415, Reward: 174.00, Epsilon: 0.443\n",
      "Episode 416, Reward: 108.00, Epsilon: 0.442\n",
      "Episode 417, Reward: 201.00, Epsilon: 0.441\n",
      "Episode 418, Reward: 225.00, Epsilon: 0.440\n",
      "Episode 419, Reward: 25.00, Epsilon: 0.439\n",
      "Episode 420, Reward: 137.00, Epsilon: 0.438\n",
      "Episode 421, Reward: 125.00, Epsilon: 0.437\n",
      "Episode 422, Reward: 16.00, Epsilon: 0.437\n",
      "Episode 423, Reward: 173.00, Epsilon: 0.436\n",
      "Episode 424, Reward: 141.00, Epsilon: 0.435\n",
      "Episode 425, Reward: 131.00, Epsilon: 0.434\n",
      "Episode 426, Reward: 187.00, Epsilon: 0.433\n",
      "Episode 427, Reward: 189.00, Epsilon: 0.432\n",
      "Episode 428, Reward: 179.00, Epsilon: 0.431\n",
      "Episode 429, Reward: 333.00, Epsilon: 0.431\n",
      "Episode 430, Reward: 203.00, Epsilon: 0.430\n",
      "Episode 431, Reward: 219.00, Epsilon: 0.429\n",
      "Episode 432, Reward: 22.00, Epsilon: 0.428\n",
      "Episode 433, Reward: 119.00, Epsilon: 0.427\n",
      "Episode 434, Reward: 284.00, Epsilon: 0.426\n",
      "Episode 435, Reward: 78.00, Epsilon: 0.426\n",
      "Episode 436, Reward: 111.00, Epsilon: 0.425\n",
      "Episode 437, Reward: 177.00, Epsilon: 0.424\n",
      "Episode 438, Reward: 155.00, Epsilon: 0.423\n",
      "Episode 439, Reward: 63.00, Epsilon: 0.422\n",
      "Episode 440, Reward: 198.00, Epsilon: 0.421\n",
      "Episode 441, Reward: 213.00, Epsilon: 0.421\n",
      "Episode 442, Reward: 46.00, Epsilon: 0.420\n",
      "Episode 443, Reward: 229.00, Epsilon: 0.419\n",
      "Episode 444, Reward: 79.00, Epsilon: 0.418\n",
      "Episode 445, Reward: 81.00, Epsilon: 0.417\n",
      "Episode 446, Reward: 42.00, Epsilon: 0.417\n",
      "Episode 447, Reward: 173.00, Epsilon: 0.416\n",
      "Episode 448, Reward: 58.00, Epsilon: 0.415\n",
      "Episode 449, Reward: 230.00, Epsilon: 0.414\n",
      "Episode 450, Reward: 155.00, Epsilon: 0.413\n",
      "Episode 451, Reward: 205.00, Epsilon: 0.413\n",
      "Episode 452, Reward: 157.00, Epsilon: 0.412\n",
      "Episode 453, Reward: 55.00, Epsilon: 0.411\n",
      "Episode 454, Reward: 151.00, Epsilon: 0.410\n",
      "Episode 455, Reward: 254.00, Epsilon: 0.409\n",
      "Episode 456, Reward: 211.00, Epsilon: 0.408\n",
      "Episode 457, Reward: 59.00, Epsilon: 0.408\n",
      "Episode 458, Reward: 41.00, Epsilon: 0.407\n",
      "Episode 459, Reward: 157.00, Epsilon: 0.406\n",
      "Episode 460, Reward: 153.00, Epsilon: 0.405\n",
      "Episode 461, Reward: 251.00, Epsilon: 0.405\n",
      "Episode 462, Reward: 16.00, Epsilon: 0.404\n",
      "Episode 463, Reward: 71.00, Epsilon: 0.403\n",
      "Episode 464, Reward: 58.00, Epsilon: 0.402\n",
      "Episode 465, Reward: 266.00, Epsilon: 0.401\n",
      "Episode 466, Reward: 361.00, Epsilon: 0.401\n",
      "Episode 467, Reward: 66.00, Epsilon: 0.400\n",
      "Episode 468, Reward: 276.00, Epsilon: 0.399\n",
      "Episode 469, Reward: 84.00, Epsilon: 0.398\n",
      "Episode 470, Reward: 173.00, Epsilon: 0.397\n",
      "Episode 471, Reward: 150.00, Epsilon: 0.397\n",
      "Episode 472, Reward: 239.00, Epsilon: 0.396\n",
      "Episode 473, Reward: 172.00, Epsilon: 0.395\n",
      "Episode 474, Reward: 28.00, Epsilon: 0.394\n",
      "Episode 475, Reward: 245.00, Epsilon: 0.394\n",
      "Episode 476, Reward: 140.00, Epsilon: 0.393\n",
      "Episode 477, Reward: 30.00, Epsilon: 0.392\n",
      "Episode 478, Reward: 230.00, Epsilon: 0.391\n",
      "Episode 479, Reward: 169.00, Epsilon: 0.391\n",
      "Episode 480, Reward: 356.00, Epsilon: 0.390\n",
      "Episode 481, Reward: 54.00, Epsilon: 0.389\n",
      "Episode 482, Reward: 204.00, Epsilon: 0.388\n",
      "Episode 483, Reward: 169.00, Epsilon: 0.388\n",
      "Episode 484, Reward: 147.00, Epsilon: 0.387\n",
      "Episode 485, Reward: 195.00, Epsilon: 0.386\n",
      "Episode 486, Reward: 111.00, Epsilon: 0.385\n",
      "Episode 487, Reward: 139.00, Epsilon: 0.385\n",
      "Episode 488, Reward: 109.00, Epsilon: 0.384\n",
      "Episode 489, Reward: 127.00, Epsilon: 0.383\n",
      "Episode 490, Reward: 167.00, Epsilon: 0.382\n",
      "Episode 491, Reward: 208.00, Epsilon: 0.382\n",
      "Episode 492, Reward: 144.00, Epsilon: 0.381\n",
      "Episode 493, Reward: 154.00, Epsilon: 0.380\n",
      "Episode 494, Reward: 271.00, Epsilon: 0.379\n",
      "Episode 495, Reward: 234.00, Epsilon: 0.379\n",
      "Episode 496, Reward: 232.00, Epsilon: 0.378\n",
      "Episode 497, Reward: 143.00, Epsilon: 0.377\n",
      "Episode 498, Reward: 230.00, Epsilon: 0.376\n",
      "Episode 499, Reward: 84.00, Epsilon: 0.376\n",
      "Episode 500, Reward: 69.00, Epsilon: 0.375\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T07:58:06.322854Z",
     "start_time": "2025-05-25T07:58:06.291292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_agent(q_net, env, episodes=20, render=False):\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()[0]\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "                action = q_net(state_tensor).argmax().item()\n",
    "\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "\n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    print(f\"\\nEvaluation over {episodes} episodes: Average Reward = {avg_reward:.2f}\")\n",
    "    return avg_reward"
   ],
   "id": "ab4cf5aea77991f6",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2025-05-25T08:15:20.196315300Z",
     "start_time": "2025-05-25T08:08:56.693447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gym\n",
    "from gym.wrappers import RecordVideo\n",
    "import os\n",
    "from IPython.display import Video\n",
    "\n",
    "def record_agent(q_net, episodes=1, video_dir='videos'):\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "    env = RecordVideo(env, video_dir=video_dir, episode_trigger=lambda x: True)\n",
    "    q_net.eval()\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()[0]\n",
    "        done = False\n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
    "                action = q_net(state_tensor).argmax().item()\n",
    "            state, _, done, _, _ = env.step(action)\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    # Return video file path\n",
    "    video_file = sorted(os.listdir(video_dir))[-1]\n",
    "    return os.path.join(video_dir, video_file)\n",
    "\n",
    "print(record_agent(q_net))"
   ],
   "id": "3f24e42322e3a1eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:05:47.265742Z",
     "start_time": "2025-05-25T08:05:38.989152Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate_agent(q_net, env, render=True)",
   "id": "de2e9545fbeafc1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation over 20 episodes: Average Reward = 288.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "288.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:08:42.645401Z",
     "start_time": "2025-05-25T08:06:30.196231Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install moviepy\n",
   "id": "47d7ed4231e6e4c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from moviepy) (5.1.1)\n",
      "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy>=1.25.0 in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.12-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting python-dotenv>=0.10 (from moviepy)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from moviepy) (11.1.0)\n",
      "Requirement already satisfied: tqdm in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from tqdm->proglog<=1.0.0->moviepy) (0.4.6)\n",
      "Downloading moviepy-2.2.1-py3-none-any.whl (129 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl (31.2 MB)\n",
      "   ---------------------------------------- 0.0/31.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/31.2 MB 4.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.6/31.2 MB 4.4 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.4/31.2 MB 3.8 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.1/31.2 MB 4.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 4.2/31.2 MB 4.1 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 5.0/31.2 MB 4.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 5.8/31.2 MB 4.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 6.8/31.2 MB 4.1 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 7.6/31.2 MB 4.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 8.4/31.2 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 9.4/31.2 MB 4.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 10.2/31.2 MB 4.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 11.0/31.2 MB 4.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 12.1/31.2 MB 4.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 13.1/31.2 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 14.2/31.2 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 15.2/31.2 MB 4.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 16.0/31.2 MB 4.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 17.0/31.2 MB 4.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 18.1/31.2 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 19.1/31.2 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 20.2/31.2 MB 4.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 21.0/31.2 MB 4.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 22.0/31.2 MB 4.5 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 23.3/31.2 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 24.4/31.2 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 25.4/31.2 MB 4.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 26.5/31.2 MB 4.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 27.5/31.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 28.8/31.2 MB 4.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 29.9/31.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  30.9/31.2 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 31.2/31.2 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading proglog-0.1.12-py3-none-any.whl (6.3 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv, imageio_ffmpeg, imageio, proglog, moviepy\n",
      "Successfully installed imageio-2.37.0 imageio_ffmpeg-0.6.0 moviepy-2.2.1 proglog-0.1.12 python-dotenv-1.1.0\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlEnv]",
   "name": "conda-env-dlEnv-py",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
