{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-25T07:56:12.339418Z",
          "start_time": "2025-05-25T07:56:12.323750Z"
        },
        "id": "d77a2f781a9383a6"
      },
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque"
      ],
      "id": "d77a2f781a9383a6",
      "outputs": [],
      "execution_count": 1
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-25T08:01:20.066763Z",
          "start_time": "2025-05-25T08:00:35.245968Z"
        },
        "id": "c12fc5b245e8481c",
        "outputId": "987dece8-5c68-4ddf-8612-c9375af570e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 1e-3\n",
        "gamma = 0.99\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay = 500\n",
        "batch_size = 64\n",
        "buffer_limit = 10000\n",
        "min_buffer = 1000\n",
        "target_update_freq = 10\n",
        "episodes = 500\n",
        "\n",
        "# Q-network\n",
        "class QNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QNet, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "# Replay buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self):\n",
        "        self.buffer = deque(maxlen=buffer_limit)\n",
        "\n",
        "    def put(self, transition):\n",
        "        self.buffer.append(transition)\n",
        "\n",
        "    def sample(self):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        s, a, r, s_prime, done = zip(*batch)\n",
        "        return (\n",
        "            torch.tensor(s, dtype=torch.float),\n",
        "            torch.tensor(a),\n",
        "            torch.tensor(r),\n",
        "            torch.tensor(s_prime, dtype=torch.float),\n",
        "            torch.tensor(done, dtype=torch.float)\n",
        "        )\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "# Epsilon-greedy policy\n",
        "def epsilon_greedy(q_net, state, epsilon):\n",
        "    if random.random() < epsilon:\n",
        "        return random.randint(0, 1)\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            state = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
        "            q_values = q_net(state)\n",
        "            return q_values.argmax().item()\n",
        "\n",
        "# Main training loop\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "q_net = QNet()\n",
        "target_net = QNet()\n",
        "target_net.load_state_dict(q_net.state_dict())\n",
        "optimizer = optim.Adam(q_net.parameters(), lr=learning_rate)\n",
        "memory = ReplayBuffer()\n",
        "\n",
        "def train(q_net, target_net, memory, optimizer):\n",
        "    s, a, r, s_prime, done = memory.sample()\n",
        "\n",
        "    q_out = q_net(s)\n",
        "    q_a = q_out.gather(1, a.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        max_q_prime = target_net(s_prime).max(1)[0]\n",
        "        target = r + gamma * max_q_prime * (1 - done)\n",
        "\n",
        "    loss = nn.MSELoss()(q_a, target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()[0]\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    epsilon = epsilon_end + (epsilon_start - epsilon_end) * np.exp(-1. * episode / epsilon_decay)\n",
        "\n",
        "    while not done:\n",
        "        action = epsilon_greedy(q_net, state, epsilon)\n",
        "        next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "        memory.put((state, action, reward, next_state, done))\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if memory.size() >= min_buffer:\n",
        "            train(q_net, target_net, memory, optimizer)\n",
        "\n",
        "    if episode % target_update_freq == 0:\n",
        "        target_net.load_state_dict(q_net.state_dict())\n",
        "\n",
        "    print(f\"Episode {episode+1}, Reward: {total_reward:.2f}, Epsilon: {epsilon:.3f}\")\n",
        "\n",
        "env.close()"
      ],
      "id": "c12fc5b245e8481c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1, Reward: 12.00, Epsilon: 1.000\n",
            "Episode 2, Reward: 13.00, Epsilon: 0.998\n",
            "Episode 3, Reward: 9.00, Epsilon: 0.996\n",
            "Episode 4, Reward: 10.00, Epsilon: 0.994\n",
            "Episode 5, Reward: 34.00, Epsilon: 0.992\n",
            "Episode 6, Reward: 34.00, Epsilon: 0.990\n",
            "Episode 7, Reward: 14.00, Epsilon: 0.988\n",
            "Episode 8, Reward: 20.00, Epsilon: 0.986\n",
            "Episode 9, Reward: 16.00, Epsilon: 0.984\n",
            "Episode 10, Reward: 11.00, Epsilon: 0.982\n",
            "Episode 11, Reward: 31.00, Epsilon: 0.980\n",
            "Episode 12, Reward: 23.00, Epsilon: 0.978\n",
            "Episode 13, Reward: 20.00, Epsilon: 0.977\n",
            "Episode 14, Reward: 13.00, Epsilon: 0.975\n",
            "Episode 15, Reward: 28.00, Epsilon: 0.973\n",
            "Episode 16, Reward: 23.00, Epsilon: 0.971\n",
            "Episode 17, Reward: 25.00, Epsilon: 0.969\n",
            "Episode 18, Reward: 10.00, Epsilon: 0.967\n",
            "Episode 19, Reward: 12.00, Epsilon: 0.965\n",
            "Episode 20, Reward: 14.00, Epsilon: 0.963\n",
            "Episode 21, Reward: 16.00, Epsilon: 0.961\n",
            "Episode 22, Reward: 27.00, Epsilon: 0.959\n",
            "Episode 23, Reward: 17.00, Epsilon: 0.957\n",
            "Episode 24, Reward: 22.00, Epsilon: 0.955\n",
            "Episode 25, Reward: 13.00, Epsilon: 0.954\n",
            "Episode 26, Reward: 11.00, Epsilon: 0.952\n",
            "Episode 27, Reward: 22.00, Epsilon: 0.950\n",
            "Episode 28, Reward: 16.00, Epsilon: 0.948\n",
            "Episode 29, Reward: 14.00, Epsilon: 0.946\n",
            "Episode 30, Reward: 36.00, Epsilon: 0.944\n",
            "Episode 31, Reward: 9.00, Epsilon: 0.942\n",
            "Episode 32, Reward: 22.00, Epsilon: 0.940\n",
            "Episode 33, Reward: 28.00, Epsilon: 0.939\n",
            "Episode 34, Reward: 27.00, Epsilon: 0.937\n",
            "Episode 35, Reward: 20.00, Epsilon: 0.935\n",
            "Episode 36, Reward: 21.00, Epsilon: 0.933\n",
            "Episode 37, Reward: 12.00, Epsilon: 0.931\n",
            "Episode 38, Reward: 18.00, Epsilon: 0.929\n",
            "Episode 39, Reward: 12.00, Epsilon: 0.928\n",
            "Episode 40, Reward: 20.00, Epsilon: 0.926\n",
            "Episode 41, Reward: 21.00, Epsilon: 0.924\n",
            "Episode 42, Reward: 26.00, Epsilon: 0.922\n",
            "Episode 43, Reward: 16.00, Epsilon: 0.920\n",
            "Episode 44, Reward: 15.00, Epsilon: 0.918\n",
            "Episode 45, Reward: 10.00, Epsilon: 0.917\n",
            "Episode 46, Reward: 19.00, Epsilon: 0.915\n",
            "Episode 47, Reward: 33.00, Epsilon: 0.913\n",
            "Episode 48, Reward: 41.00, Epsilon: 0.911\n",
            "Episode 49, Reward: 14.00, Epsilon: 0.909\n",
            "Episode 50, Reward: 12.00, Epsilon: 0.908\n",
            "Episode 51, Reward: 15.00, Epsilon: 0.906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-622876f2dc5b>:38: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  torch.tensor(s, dtype=torch.float),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 52, Reward: 68.00, Epsilon: 0.904\n",
            "Episode 53, Reward: 24.00, Epsilon: 0.902\n",
            "Episode 54, Reward: 27.00, Epsilon: 0.900\n",
            "Episode 55, Reward: 32.00, Epsilon: 0.899\n",
            "Episode 56, Reward: 11.00, Epsilon: 0.897\n",
            "Episode 57, Reward: 42.00, Epsilon: 0.895\n",
            "Episode 58, Reward: 27.00, Epsilon: 0.893\n",
            "Episode 59, Reward: 15.00, Epsilon: 0.892\n",
            "Episode 60, Reward: 27.00, Epsilon: 0.890\n",
            "Episode 61, Reward: 29.00, Epsilon: 0.888\n",
            "Episode 62, Reward: 9.00, Epsilon: 0.886\n",
            "Episode 63, Reward: 23.00, Epsilon: 0.885\n",
            "Episode 64, Reward: 23.00, Epsilon: 0.883\n",
            "Episode 65, Reward: 47.00, Epsilon: 0.881\n",
            "Episode 66, Reward: 16.00, Epsilon: 0.879\n",
            "Episode 67, Reward: 21.00, Epsilon: 0.878\n",
            "Episode 68, Reward: 19.00, Epsilon: 0.876\n",
            "Episode 69, Reward: 10.00, Epsilon: 0.874\n",
            "Episode 70, Reward: 17.00, Epsilon: 0.872\n",
            "Episode 71, Reward: 21.00, Epsilon: 0.871\n",
            "Episode 72, Reward: 14.00, Epsilon: 0.869\n",
            "Episode 73, Reward: 18.00, Epsilon: 0.867\n",
            "Episode 74, Reward: 18.00, Epsilon: 0.866\n",
            "Episode 75, Reward: 42.00, Epsilon: 0.864\n",
            "Episode 76, Reward: 29.00, Epsilon: 0.862\n",
            "Episode 77, Reward: 16.00, Epsilon: 0.860\n",
            "Episode 78, Reward: 14.00, Epsilon: 0.859\n",
            "Episode 79, Reward: 11.00, Epsilon: 0.857\n",
            "Episode 80, Reward: 18.00, Epsilon: 0.855\n",
            "Episode 81, Reward: 17.00, Epsilon: 0.854\n",
            "Episode 82, Reward: 13.00, Epsilon: 0.852\n",
            "Episode 83, Reward: 28.00, Epsilon: 0.850\n",
            "Episode 84, Reward: 13.00, Epsilon: 0.849\n",
            "Episode 85, Reward: 24.00, Epsilon: 0.847\n",
            "Episode 86, Reward: 29.00, Epsilon: 0.845\n",
            "Episode 87, Reward: 13.00, Epsilon: 0.844\n",
            "Episode 88, Reward: 35.00, Epsilon: 0.842\n",
            "Episode 89, Reward: 18.00, Epsilon: 0.840\n",
            "Episode 90, Reward: 20.00, Epsilon: 0.839\n",
            "Episode 91, Reward: 32.00, Epsilon: 0.837\n",
            "Episode 92, Reward: 20.00, Epsilon: 0.835\n",
            "Episode 93, Reward: 33.00, Epsilon: 0.834\n",
            "Episode 94, Reward: 17.00, Epsilon: 0.832\n",
            "Episode 95, Reward: 23.00, Epsilon: 0.830\n",
            "Episode 96, Reward: 32.00, Epsilon: 0.829\n",
            "Episode 97, Reward: 14.00, Epsilon: 0.827\n",
            "Episode 98, Reward: 23.00, Epsilon: 0.825\n",
            "Episode 99, Reward: 18.00, Epsilon: 0.824\n",
            "Episode 100, Reward: 17.00, Epsilon: 0.822\n",
            "Episode 101, Reward: 16.00, Epsilon: 0.821\n",
            "Episode 102, Reward: 18.00, Epsilon: 0.819\n",
            "Episode 103, Reward: 19.00, Epsilon: 0.817\n",
            "Episode 104, Reward: 14.00, Epsilon: 0.816\n",
            "Episode 105, Reward: 20.00, Epsilon: 0.814\n",
            "Episode 106, Reward: 17.00, Epsilon: 0.812\n",
            "Episode 107, Reward: 67.00, Epsilon: 0.811\n",
            "Episode 108, Reward: 14.00, Epsilon: 0.809\n",
            "Episode 109, Reward: 23.00, Epsilon: 0.808\n",
            "Episode 110, Reward: 14.00, Epsilon: 0.806\n",
            "Episode 111, Reward: 42.00, Epsilon: 0.804\n",
            "Episode 112, Reward: 29.00, Epsilon: 0.803\n",
            "Episode 113, Reward: 52.00, Epsilon: 0.801\n",
            "Episode 114, Reward: 54.00, Epsilon: 0.800\n",
            "Episode 115, Reward: 51.00, Epsilon: 0.798\n",
            "Episode 116, Reward: 35.00, Epsilon: 0.797\n",
            "Episode 117, Reward: 10.00, Epsilon: 0.795\n",
            "Episode 118, Reward: 28.00, Epsilon: 0.793\n",
            "Episode 119, Reward: 111.00, Epsilon: 0.792\n",
            "Episode 120, Reward: 10.00, Epsilon: 0.790\n",
            "Episode 121, Reward: 23.00, Epsilon: 0.789\n",
            "Episode 122, Reward: 14.00, Epsilon: 0.787\n",
            "Episode 123, Reward: 29.00, Epsilon: 0.786\n",
            "Episode 124, Reward: 25.00, Epsilon: 0.784\n",
            "Episode 125, Reward: 37.00, Epsilon: 0.783\n",
            "Episode 126, Reward: 53.00, Epsilon: 0.781\n",
            "Episode 127, Reward: 47.00, Epsilon: 0.779\n",
            "Episode 128, Reward: 11.00, Epsilon: 0.778\n",
            "Episode 129, Reward: 80.00, Epsilon: 0.776\n",
            "Episode 130, Reward: 12.00, Epsilon: 0.775\n",
            "Episode 131, Reward: 40.00, Epsilon: 0.773\n",
            "Episode 132, Reward: 25.00, Epsilon: 0.772\n",
            "Episode 133, Reward: 13.00, Epsilon: 0.770\n",
            "Episode 134, Reward: 52.00, Epsilon: 0.769\n",
            "Episode 135, Reward: 37.00, Epsilon: 0.767\n",
            "Episode 136, Reward: 27.00, Epsilon: 0.766\n",
            "Episode 137, Reward: 45.00, Epsilon: 0.764\n",
            "Episode 138, Reward: 37.00, Epsilon: 0.763\n",
            "Episode 139, Reward: 106.00, Epsilon: 0.761\n",
            "Episode 140, Reward: 167.00, Epsilon: 0.760\n",
            "Episode 141, Reward: 35.00, Epsilon: 0.758\n",
            "Episode 142, Reward: 20.00, Epsilon: 0.757\n",
            "Episode 143, Reward: 53.00, Epsilon: 0.755\n",
            "Episode 144, Reward: 14.00, Epsilon: 0.754\n",
            "Episode 145, Reward: 55.00, Epsilon: 0.752\n",
            "Episode 146, Reward: 17.00, Epsilon: 0.751\n",
            "Episode 147, Reward: 83.00, Epsilon: 0.749\n",
            "Episode 148, Reward: 33.00, Epsilon: 0.748\n",
            "Episode 149, Reward: 27.00, Epsilon: 0.746\n",
            "Episode 150, Reward: 37.00, Epsilon: 0.745\n",
            "Episode 151, Reward: 13.00, Epsilon: 0.743\n",
            "Episode 152, Reward: 51.00, Epsilon: 0.742\n",
            "Episode 153, Reward: 36.00, Epsilon: 0.740\n",
            "Episode 154, Reward: 96.00, Epsilon: 0.739\n",
            "Episode 155, Reward: 12.00, Epsilon: 0.738\n",
            "Episode 156, Reward: 57.00, Epsilon: 0.736\n",
            "Episode 157, Reward: 34.00, Epsilon: 0.735\n",
            "Episode 158, Reward: 12.00, Epsilon: 0.733\n",
            "Episode 159, Reward: 21.00, Epsilon: 0.732\n",
            "Episode 160, Reward: 42.00, Epsilon: 0.730\n",
            "Episode 161, Reward: 68.00, Epsilon: 0.729\n",
            "Episode 162, Reward: 66.00, Epsilon: 0.727\n",
            "Episode 163, Reward: 98.00, Epsilon: 0.726\n",
            "Episode 164, Reward: 68.00, Epsilon: 0.725\n",
            "Episode 165, Reward: 22.00, Epsilon: 0.723\n",
            "Episode 166, Reward: 53.00, Epsilon: 0.722\n",
            "Episode 167, Reward: 74.00, Epsilon: 0.720\n",
            "Episode 168, Reward: 54.00, Epsilon: 0.719\n",
            "Episode 169, Reward: 76.00, Epsilon: 0.717\n",
            "Episode 170, Reward: 131.00, Epsilon: 0.716\n",
            "Episode 171, Reward: 95.00, Epsilon: 0.715\n",
            "Episode 172, Reward: 52.00, Epsilon: 0.713\n",
            "Episode 173, Reward: 54.00, Epsilon: 0.712\n",
            "Episode 174, Reward: 28.00, Epsilon: 0.710\n",
            "Episode 175, Reward: 85.00, Epsilon: 0.709\n",
            "Episode 176, Reward: 72.00, Epsilon: 0.708\n",
            "Episode 177, Reward: 54.00, Epsilon: 0.706\n",
            "Episode 178, Reward: 30.00, Epsilon: 0.705\n",
            "Episode 179, Reward: 134.00, Epsilon: 0.703\n",
            "Episode 180, Reward: 20.00, Epsilon: 0.702\n",
            "Episode 181, Reward: 87.00, Epsilon: 0.701\n",
            "Episode 182, Reward: 55.00, Epsilon: 0.699\n",
            "Episode 183, Reward: 141.00, Epsilon: 0.698\n",
            "Episode 184, Reward: 13.00, Epsilon: 0.697\n",
            "Episode 185, Reward: 25.00, Epsilon: 0.695\n",
            "Episode 186, Reward: 27.00, Epsilon: 0.694\n",
            "Episode 187, Reward: 65.00, Epsilon: 0.692\n",
            "Episode 188, Reward: 35.00, Epsilon: 0.691\n",
            "Episode 189, Reward: 36.00, Epsilon: 0.690\n",
            "Episode 190, Reward: 74.00, Epsilon: 0.688\n",
            "Episode 191, Reward: 20.00, Epsilon: 0.687\n",
            "Episode 192, Reward: 65.00, Epsilon: 0.686\n",
            "Episode 193, Reward: 28.00, Epsilon: 0.684\n",
            "Episode 194, Reward: 50.00, Epsilon: 0.683\n",
            "Episode 195, Reward: 32.00, Epsilon: 0.682\n",
            "Episode 196, Reward: 40.00, Epsilon: 0.680\n",
            "Episode 197, Reward: 54.00, Epsilon: 0.679\n",
            "Episode 198, Reward: 99.00, Epsilon: 0.678\n",
            "Episode 199, Reward: 39.00, Epsilon: 0.676\n",
            "Episode 200, Reward: 20.00, Epsilon: 0.675\n",
            "Episode 201, Reward: 113.00, Epsilon: 0.674\n",
            "Episode 202, Reward: 40.00, Epsilon: 0.672\n",
            "Episode 203, Reward: 67.00, Epsilon: 0.671\n",
            "Episode 204, Reward: 26.00, Epsilon: 0.670\n",
            "Episode 205, Reward: 86.00, Epsilon: 0.668\n",
            "Episode 206, Reward: 49.00, Epsilon: 0.667\n",
            "Episode 207, Reward: 26.00, Epsilon: 0.666\n",
            "Episode 208, Reward: 12.00, Epsilon: 0.664\n",
            "Episode 209, Reward: 55.00, Epsilon: 0.663\n",
            "Episode 210, Reward: 10.00, Epsilon: 0.662\n",
            "Episode 211, Reward: 70.00, Epsilon: 0.660\n",
            "Episode 212, Reward: 54.00, Epsilon: 0.659\n",
            "Episode 213, Reward: 51.00, Epsilon: 0.658\n",
            "Episode 214, Reward: 168.00, Epsilon: 0.657\n",
            "Episode 215, Reward: 18.00, Epsilon: 0.655\n",
            "Episode 216, Reward: 74.00, Epsilon: 0.654\n",
            "Episode 217, Reward: 68.00, Epsilon: 0.653\n",
            "Episode 218, Reward: 23.00, Epsilon: 0.651\n",
            "Episode 219, Reward: 108.00, Epsilon: 0.650\n",
            "Episode 220, Reward: 89.00, Epsilon: 0.649\n",
            "Episode 221, Reward: 17.00, Epsilon: 0.648\n",
            "Episode 222, Reward: 102.00, Epsilon: 0.646\n",
            "Episode 223, Reward: 14.00, Epsilon: 0.645\n",
            "Episode 224, Reward: 43.00, Epsilon: 0.644\n",
            "Episode 225, Reward: 71.00, Epsilon: 0.643\n",
            "Episode 226, Reward: 41.00, Epsilon: 0.641\n",
            "Episode 227, Reward: 66.00, Epsilon: 0.640\n",
            "Episode 228, Reward: 47.00, Epsilon: 0.639\n",
            "Episode 229, Reward: 66.00, Epsilon: 0.637\n",
            "Episode 230, Reward: 41.00, Epsilon: 0.636\n",
            "Episode 231, Reward: 61.00, Epsilon: 0.635\n",
            "Episode 232, Reward: 99.00, Epsilon: 0.634\n",
            "Episode 233, Reward: 175.00, Epsilon: 0.632\n",
            "Episode 234, Reward: 92.00, Epsilon: 0.631\n",
            "Episode 235, Reward: 56.00, Epsilon: 0.630\n",
            "Episode 236, Reward: 79.00, Epsilon: 0.629\n",
            "Episode 237, Reward: 44.00, Epsilon: 0.628\n",
            "Episode 238, Reward: 20.00, Epsilon: 0.626\n",
            "Episode 239, Reward: 19.00, Epsilon: 0.625\n",
            "Episode 240, Reward: 24.00, Epsilon: 0.624\n",
            "Episode 241, Reward: 41.00, Epsilon: 0.623\n",
            "Episode 242, Reward: 10.00, Epsilon: 0.621\n",
            "Episode 243, Reward: 135.00, Epsilon: 0.620\n",
            "Episode 244, Reward: 53.00, Epsilon: 0.619\n",
            "Episode 245, Reward: 76.00, Epsilon: 0.618\n",
            "Episode 246, Reward: 10.00, Epsilon: 0.617\n",
            "Episode 247, Reward: 98.00, Epsilon: 0.615\n",
            "Episode 248, Reward: 53.00, Epsilon: 0.614\n",
            "Episode 249, Reward: 178.00, Epsilon: 0.613\n",
            "Episode 250, Reward: 36.00, Epsilon: 0.612\n",
            "Episode 251, Reward: 123.00, Epsilon: 0.610\n",
            "Episode 252, Reward: 42.00, Epsilon: 0.609\n",
            "Episode 253, Reward: 136.00, Epsilon: 0.608\n",
            "Episode 254, Reward: 58.00, Epsilon: 0.607\n",
            "Episode 255, Reward: 66.00, Epsilon: 0.606\n",
            "Episode 256, Reward: 22.00, Epsilon: 0.604\n",
            "Episode 257, Reward: 47.00, Epsilon: 0.603\n",
            "Episode 258, Reward: 18.00, Epsilon: 0.602\n",
            "Episode 259, Reward: 49.00, Epsilon: 0.601\n",
            "Episode 260, Reward: 24.00, Epsilon: 0.600\n",
            "Episode 261, Reward: 13.00, Epsilon: 0.599\n",
            "Episode 262, Reward: 120.00, Epsilon: 0.597\n",
            "Episode 263, Reward: 38.00, Epsilon: 0.596\n",
            "Episode 264, Reward: 99.00, Epsilon: 0.595\n",
            "Episode 265, Reward: 18.00, Epsilon: 0.594\n",
            "Episode 266, Reward: 169.00, Epsilon: 0.593\n",
            "Episode 267, Reward: 117.00, Epsilon: 0.592\n",
            "Episode 268, Reward: 129.00, Epsilon: 0.590\n",
            "Episode 269, Reward: 42.00, Epsilon: 0.589\n",
            "Episode 270, Reward: 21.00, Epsilon: 0.588\n",
            "Episode 271, Reward: 46.00, Epsilon: 0.587\n",
            "Episode 272, Reward: 80.00, Epsilon: 0.586\n",
            "Episode 273, Reward: 23.00, Epsilon: 0.585\n",
            "Episode 274, Reward: 28.00, Epsilon: 0.583\n",
            "Episode 275, Reward: 103.00, Epsilon: 0.582\n",
            "Episode 276, Reward: 89.00, Epsilon: 0.581\n",
            "Episode 277, Reward: 20.00, Epsilon: 0.580\n",
            "Episode 278, Reward: 86.00, Epsilon: 0.579\n",
            "Episode 279, Reward: 86.00, Epsilon: 0.578\n",
            "Episode 280, Reward: 25.00, Epsilon: 0.577\n",
            "Episode 281, Reward: 125.00, Epsilon: 0.575\n",
            "Episode 282, Reward: 31.00, Epsilon: 0.574\n",
            "Episode 283, Reward: 60.00, Epsilon: 0.573\n",
            "Episode 284, Reward: 131.00, Epsilon: 0.572\n",
            "Episode 285, Reward: 183.00, Epsilon: 0.571\n",
            "Episode 286, Reward: 104.00, Epsilon: 0.570\n",
            "Episode 287, Reward: 40.00, Epsilon: 0.569\n",
            "Episode 288, Reward: 22.00, Epsilon: 0.568\n",
            "Episode 289, Reward: 128.00, Epsilon: 0.567\n",
            "Episode 290, Reward: 111.00, Epsilon: 0.565\n",
            "Episode 291, Reward: 137.00, Epsilon: 0.564\n",
            "Episode 292, Reward: 125.00, Epsilon: 0.563\n",
            "Episode 293, Reward: 86.00, Epsilon: 0.562\n",
            "Episode 294, Reward: 11.00, Epsilon: 0.561\n",
            "Episode 295, Reward: 56.00, Epsilon: 0.560\n",
            "Episode 296, Reward: 44.00, Epsilon: 0.559\n",
            "Episode 297, Reward: 154.00, Epsilon: 0.558\n",
            "Episode 298, Reward: 21.00, Epsilon: 0.557\n",
            "Episode 299, Reward: 202.00, Epsilon: 0.556\n",
            "Episode 300, Reward: 122.00, Epsilon: 0.554\n",
            "Episode 301, Reward: 106.00, Epsilon: 0.553\n",
            "Episode 302, Reward: 166.00, Epsilon: 0.552\n",
            "Episode 303, Reward: 71.00, Epsilon: 0.551\n",
            "Episode 304, Reward: 150.00, Epsilon: 0.550\n",
            "Episode 305, Reward: 122.00, Epsilon: 0.549\n",
            "Episode 306, Reward: 113.00, Epsilon: 0.548\n",
            "Episode 307, Reward: 226.00, Epsilon: 0.547\n",
            "Episode 308, Reward: 21.00, Epsilon: 0.546\n",
            "Episode 309, Reward: 88.00, Epsilon: 0.545\n",
            "Episode 310, Reward: 43.00, Epsilon: 0.544\n",
            "Episode 311, Reward: 35.00, Epsilon: 0.543\n",
            "Episode 312, Reward: 38.00, Epsilon: 0.542\n",
            "Episode 313, Reward: 33.00, Epsilon: 0.540\n",
            "Episode 314, Reward: 146.00, Epsilon: 0.539\n",
            "Episode 315, Reward: 85.00, Epsilon: 0.538\n",
            "Episode 316, Reward: 151.00, Epsilon: 0.537\n",
            "Episode 317, Reward: 47.00, Epsilon: 0.536\n",
            "Episode 318, Reward: 101.00, Epsilon: 0.535\n",
            "Episode 319, Reward: 199.00, Epsilon: 0.534\n",
            "Episode 320, Reward: 60.00, Epsilon: 0.533\n",
            "Episode 321, Reward: 143.00, Epsilon: 0.532\n",
            "Episode 322, Reward: 47.00, Epsilon: 0.531\n",
            "Episode 323, Reward: 157.00, Epsilon: 0.530\n",
            "Episode 324, Reward: 121.00, Epsilon: 0.529\n",
            "Episode 325, Reward: 15.00, Epsilon: 0.528\n",
            "Episode 326, Reward: 47.00, Epsilon: 0.527\n",
            "Episode 327, Reward: 216.00, Epsilon: 0.526\n",
            "Episode 328, Reward: 145.00, Epsilon: 0.525\n",
            "Episode 329, Reward: 14.00, Epsilon: 0.524\n",
            "Episode 330, Reward: 223.00, Epsilon: 0.523\n",
            "Episode 331, Reward: 41.00, Epsilon: 0.522\n",
            "Episode 332, Reward: 63.00, Epsilon: 0.521\n",
            "Episode 333, Reward: 27.00, Epsilon: 0.520\n",
            "Episode 334, Reward: 155.00, Epsilon: 0.519\n",
            "Episode 335, Reward: 55.00, Epsilon: 0.518\n",
            "Episode 336, Reward: 194.00, Epsilon: 0.517\n",
            "Episode 337, Reward: 78.00, Epsilon: 0.516\n",
            "Episode 338, Reward: 42.00, Epsilon: 0.515\n",
            "Episode 339, Reward: 33.00, Epsilon: 0.514\n",
            "Episode 340, Reward: 162.00, Epsilon: 0.513\n",
            "Episode 341, Reward: 36.00, Epsilon: 0.512\n",
            "Episode 342, Reward: 122.00, Epsilon: 0.511\n",
            "Episode 343, Reward: 200.00, Epsilon: 0.510\n",
            "Episode 344, Reward: 115.00, Epsilon: 0.509\n",
            "Episode 345, Reward: 67.00, Epsilon: 0.508\n",
            "Episode 346, Reward: 188.00, Epsilon: 0.507\n",
            "Episode 347, Reward: 89.00, Epsilon: 0.506\n",
            "Episode 348, Reward: 171.00, Epsilon: 0.505\n",
            "Episode 349, Reward: 53.00, Epsilon: 0.504\n",
            "Episode 350, Reward: 159.00, Epsilon: 0.503\n",
            "Episode 351, Reward: 19.00, Epsilon: 0.502\n",
            "Episode 352, Reward: 249.00, Epsilon: 0.501\n",
            "Episode 353, Reward: 183.00, Epsilon: 0.500\n",
            "Episode 354, Reward: 77.00, Epsilon: 0.499\n",
            "Episode 355, Reward: 83.00, Epsilon: 0.498\n",
            "Episode 356, Reward: 93.00, Epsilon: 0.497\n",
            "Episode 357, Reward: 84.00, Epsilon: 0.496\n",
            "Episode 358, Reward: 140.00, Epsilon: 0.495\n",
            "Episode 359, Reward: 213.00, Epsilon: 0.494\n",
            "Episode 360, Reward: 165.00, Epsilon: 0.493\n",
            "Episode 361, Reward: 27.00, Epsilon: 0.492\n",
            "Episode 362, Reward: 22.00, Epsilon: 0.491\n",
            "Episode 363, Reward: 149.00, Epsilon: 0.490\n",
            "Episode 364, Reward: 249.00, Epsilon: 0.489\n",
            "Episode 365, Reward: 86.00, Epsilon: 0.488\n",
            "Episode 366, Reward: 209.00, Epsilon: 0.487\n",
            "Episode 367, Reward: 33.00, Epsilon: 0.486\n",
            "Episode 368, Reward: 86.00, Epsilon: 0.485\n",
            "Episode 369, Reward: 225.00, Epsilon: 0.484\n",
            "Episode 370, Reward: 58.00, Epsilon: 0.483\n",
            "Episode 371, Reward: 204.00, Epsilon: 0.482\n",
            "Episode 372, Reward: 282.00, Epsilon: 0.481\n",
            "Episode 373, Reward: 130.00, Epsilon: 0.480\n",
            "Episode 374, Reward: 78.00, Epsilon: 0.480\n",
            "Episode 375, Reward: 235.00, Epsilon: 0.479\n",
            "Episode 376, Reward: 32.00, Epsilon: 0.478\n",
            "Episode 377, Reward: 54.00, Epsilon: 0.477\n",
            "Episode 378, Reward: 24.00, Epsilon: 0.476\n",
            "Episode 379, Reward: 150.00, Epsilon: 0.475\n",
            "Episode 380, Reward: 203.00, Epsilon: 0.474\n",
            "Episode 381, Reward: 45.00, Epsilon: 0.473\n",
            "Episode 382, Reward: 339.00, Epsilon: 0.472\n",
            "Episode 383, Reward: 48.00, Epsilon: 0.471\n",
            "Episode 384, Reward: 268.00, Epsilon: 0.470\n",
            "Episode 385, Reward: 46.00, Epsilon: 0.469\n",
            "Episode 386, Reward: 46.00, Epsilon: 0.468\n",
            "Episode 387, Reward: 30.00, Epsilon: 0.467\n",
            "Episode 388, Reward: 126.00, Epsilon: 0.467\n",
            "Episode 389, Reward: 199.00, Epsilon: 0.466\n",
            "Episode 390, Reward: 35.00, Epsilon: 0.465\n",
            "Episode 391, Reward: 290.00, Epsilon: 0.464\n",
            "Episode 392, Reward: 151.00, Epsilon: 0.463\n",
            "Episode 393, Reward: 76.00, Epsilon: 0.462\n",
            "Episode 394, Reward: 101.00, Epsilon: 0.461\n",
            "Episode 395, Reward: 69.00, Epsilon: 0.460\n",
            "Episode 396, Reward: 97.00, Epsilon: 0.459\n",
            "Episode 397, Reward: 295.00, Epsilon: 0.458\n",
            "Episode 398, Reward: 63.00, Epsilon: 0.458\n",
            "Episode 399, Reward: 58.00, Epsilon: 0.457\n",
            "Episode 400, Reward: 75.00, Epsilon: 0.456\n",
            "Episode 401, Reward: 172.00, Epsilon: 0.455\n",
            "Episode 402, Reward: 89.00, Epsilon: 0.454\n",
            "Episode 403, Reward: 27.00, Epsilon: 0.453\n",
            "Episode 404, Reward: 30.00, Epsilon: 0.452\n",
            "Episode 405, Reward: 137.00, Epsilon: 0.451\n",
            "Episode 406, Reward: 178.00, Epsilon: 0.450\n",
            "Episode 407, Reward: 94.00, Epsilon: 0.450\n",
            "Episode 408, Reward: 195.00, Epsilon: 0.449\n",
            "Episode 409, Reward: 74.00, Epsilon: 0.448\n",
            "Episode 410, Reward: 46.00, Epsilon: 0.447\n",
            "Episode 411, Reward: 114.00, Epsilon: 0.446\n",
            "Episode 412, Reward: 152.00, Epsilon: 0.445\n",
            "Episode 413, Reward: 67.00, Epsilon: 0.444\n",
            "Episode 414, Reward: 30.00, Epsilon: 0.443\n",
            "Episode 415, Reward: 51.00, Epsilon: 0.443\n",
            "Episode 416, Reward: 34.00, Epsilon: 0.442\n",
            "Episode 417, Reward: 329.00, Epsilon: 0.441\n",
            "Episode 418, Reward: 192.00, Epsilon: 0.440\n",
            "Episode 419, Reward: 260.00, Epsilon: 0.439\n",
            "Episode 420, Reward: 13.00, Epsilon: 0.438\n",
            "Episode 421, Reward: 51.00, Epsilon: 0.437\n",
            "Episode 422, Reward: 21.00, Epsilon: 0.437\n",
            "Episode 423, Reward: 31.00, Epsilon: 0.436\n",
            "Episode 424, Reward: 64.00, Epsilon: 0.435\n",
            "Episode 425, Reward: 152.00, Epsilon: 0.434\n",
            "Episode 426, Reward: 396.00, Epsilon: 0.433\n",
            "Episode 427, Reward: 169.00, Epsilon: 0.432\n",
            "Episode 428, Reward: 300.00, Epsilon: 0.431\n",
            "Episode 429, Reward: 367.00, Epsilon: 0.431\n",
            "Episode 430, Reward: 307.00, Epsilon: 0.430\n",
            "Episode 431, Reward: 255.00, Epsilon: 0.429\n",
            "Episode 432, Reward: 86.00, Epsilon: 0.428\n",
            "Episode 433, Reward: 164.00, Epsilon: 0.427\n",
            "Episode 434, Reward: 41.00, Epsilon: 0.426\n",
            "Episode 435, Reward: 124.00, Epsilon: 0.426\n",
            "Episode 436, Reward: 141.00, Epsilon: 0.425\n",
            "Episode 437, Reward: 170.00, Epsilon: 0.424\n",
            "Episode 438, Reward: 286.00, Epsilon: 0.423\n",
            "Episode 439, Reward: 56.00, Epsilon: 0.422\n",
            "Episode 440, Reward: 306.00, Epsilon: 0.421\n",
            "Episode 441, Reward: 115.00, Epsilon: 0.421\n",
            "Episode 442, Reward: 16.00, Epsilon: 0.420\n",
            "Episode 443, Reward: 229.00, Epsilon: 0.419\n",
            "Episode 444, Reward: 68.00, Epsilon: 0.418\n",
            "Episode 445, Reward: 50.00, Epsilon: 0.417\n",
            "Episode 446, Reward: 53.00, Epsilon: 0.417\n",
            "Episode 447, Reward: 194.00, Epsilon: 0.416\n",
            "Episode 448, Reward: 182.00, Epsilon: 0.415\n",
            "Episode 449, Reward: 157.00, Epsilon: 0.414\n",
            "Episode 450, Reward: 157.00, Epsilon: 0.413\n",
            "Episode 451, Reward: 143.00, Epsilon: 0.413\n",
            "Episode 452, Reward: 216.00, Epsilon: 0.412\n",
            "Episode 453, Reward: 50.00, Epsilon: 0.411\n",
            "Episode 454, Reward: 30.00, Epsilon: 0.410\n",
            "Episode 455, Reward: 201.00, Epsilon: 0.409\n",
            "Episode 456, Reward: 15.00, Epsilon: 0.408\n",
            "Episode 457, Reward: 129.00, Epsilon: 0.408\n",
            "Episode 458, Reward: 190.00, Epsilon: 0.407\n",
            "Episode 459, Reward: 74.00, Epsilon: 0.406\n",
            "Episode 460, Reward: 217.00, Epsilon: 0.405\n",
            "Episode 461, Reward: 162.00, Epsilon: 0.405\n",
            "Episode 462, Reward: 64.00, Epsilon: 0.404\n",
            "Episode 463, Reward: 207.00, Epsilon: 0.403\n",
            "Episode 464, Reward: 130.00, Epsilon: 0.402\n",
            "Episode 465, Reward: 308.00, Epsilon: 0.401\n",
            "Episode 466, Reward: 60.00, Epsilon: 0.401\n",
            "Episode 467, Reward: 76.00, Epsilon: 0.400\n",
            "Episode 468, Reward: 146.00, Epsilon: 0.399\n",
            "Episode 469, Reward: 261.00, Epsilon: 0.398\n",
            "Episode 470, Reward: 162.00, Epsilon: 0.397\n",
            "Episode 471, Reward: 49.00, Epsilon: 0.397\n",
            "Episode 472, Reward: 378.00, Epsilon: 0.396\n",
            "Episode 473, Reward: 133.00, Epsilon: 0.395\n",
            "Episode 474, Reward: 141.00, Epsilon: 0.394\n",
            "Episode 475, Reward: 135.00, Epsilon: 0.394\n",
            "Episode 476, Reward: 277.00, Epsilon: 0.393\n",
            "Episode 477, Reward: 108.00, Epsilon: 0.392\n",
            "Episode 478, Reward: 31.00, Epsilon: 0.391\n",
            "Episode 479, Reward: 126.00, Epsilon: 0.391\n",
            "Episode 480, Reward: 236.00, Epsilon: 0.390\n",
            "Episode 481, Reward: 262.00, Epsilon: 0.389\n",
            "Episode 482, Reward: 67.00, Epsilon: 0.388\n",
            "Episode 483, Reward: 168.00, Epsilon: 0.388\n",
            "Episode 484, Reward: 264.00, Epsilon: 0.387\n",
            "Episode 485, Reward: 165.00, Epsilon: 0.386\n",
            "Episode 486, Reward: 75.00, Epsilon: 0.385\n",
            "Episode 487, Reward: 115.00, Epsilon: 0.385\n",
            "Episode 488, Reward: 242.00, Epsilon: 0.384\n",
            "Episode 489, Reward: 370.00, Epsilon: 0.383\n",
            "Episode 490, Reward: 65.00, Epsilon: 0.382\n",
            "Episode 491, Reward: 243.00, Epsilon: 0.382\n",
            "Episode 492, Reward: 299.00, Epsilon: 0.381\n",
            "Episode 493, Reward: 379.00, Epsilon: 0.380\n",
            "Episode 494, Reward: 109.00, Epsilon: 0.379\n",
            "Episode 495, Reward: 281.00, Epsilon: 0.379\n",
            "Episode 496, Reward: 345.00, Epsilon: 0.378\n",
            "Episode 497, Reward: 282.00, Epsilon: 0.377\n",
            "Episode 498, Reward: 34.00, Epsilon: 0.376\n",
            "Episode 499, Reward: 168.00, Epsilon: 0.376\n",
            "Episode 500, Reward: 195.00, Epsilon: 0.375\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-25T07:58:06.322854Z",
          "start_time": "2025-05-25T07:58:06.291292Z"
        },
        "id": "ab4cf5aea77991f6"
      },
      "cell_type": "code",
      "source": [
        "def evaluate_agent(q_net, env, episodes=20, render=False):\n",
        "    total_rewards = []\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()[0]\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            if render:\n",
        "                env.render()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
        "                action = q_net(state_tensor).argmax().item()\n",
        "\n",
        "            next_state, reward, done, _, _ = env.step(action)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "        total_rewards.append(total_reward)\n",
        "\n",
        "    avg_reward = np.mean(total_rewards)\n",
        "    print(f\"\\nEvaluation over {episodes} episodes: Average Reward = {avg_reward:.2f}\")\n",
        "    return avg_reward"
      ],
      "id": "ab4cf5aea77991f6",
      "outputs": [],
      "execution_count": 3
    },
    {
      "metadata": {
        "jupyter": {
          "is_executing": true
        },
        "ExecuteTime": {
          "end_time": "2025-05-25T08:15:20.196315300Z",
          "start_time": "2025-05-25T08:08:56.693447Z"
        },
        "id": "3f24e42322e3a1eb",
        "outputId": "a79c2d23-d329-4e3d-b0d0-34377a55ac47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# import gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import os\n",
        "from IPython.display import Video\n",
        "\n",
        "def record_agent(q_net, episodes=10, video_dir='videos'):\n",
        "    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "    env = RecordVideo(env, video_dir, episode_trigger=lambda x: True)\n",
        "    q_net.eval()\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()[0]\n",
        "        done = False\n",
        "        while not done:\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.tensor(state, dtype=torch.float).unsqueeze(0)\n",
        "                action = q_net(state_tensor).argmax().item()\n",
        "            state, _, done, _, _ = env.step(action)\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    # Return video file path\n",
        "    video_file = sorted(os.listdir(video_dir))[-1]\n",
        "    return os.path.join(video_dir, video_file)\n",
        "\n",
        "print(record_agent(q_net))"
      ],
      "id": "3f24e42322e3a1eb",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "videos/rl-video-episode-9.mp4\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-25T08:05:47.265742Z",
          "start_time": "2025-05-25T08:05:38.989152Z"
        },
        "id": "de2e9545fbeafc1d",
        "outputId": "6e70b81e-113d-448a-c718-18f5799cd012"
      },
      "cell_type": "code",
      "source": [
        "evaluate_agent(q_net, env, render=True)"
      ],
      "id": "de2e9545fbeafc1d",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation over 20 episodes: Average Reward = 288.00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "288.0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-25T08:08:42.645401Z",
          "start_time": "2025-05-25T08:06:30.196231Z"
        },
        "id": "47d7ed4231e6e4c3",
        "outputId": "7e88123b-b7da-49e5-b77d-d10ebbf03f70"
      },
      "cell_type": "code",
      "source": [
        "!pip install moviepy\n"
      ],
      "id": "47d7ed4231e6e4c3",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting moviepy\n",
            "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: decorator<6.0,>=4.0.2 in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from moviepy) (5.1.1)\n",
            "Collecting imageio<3.0,>=2.5 (from moviepy)\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
            "  Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy>=1.25.0 in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from moviepy) (1.26.4)\n",
            "Collecting proglog<=1.0.0 (from moviepy)\n",
            "  Downloading proglog-0.1.12-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting python-dotenv>=0.10 (from moviepy)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pillow<12.0,>=9.2.0 in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from moviepy) (11.1.0)\n",
            "Requirement already satisfied: tqdm in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
            "Requirement already satisfied: colorama in d:\\software\\conda\\envs\\dlenv\\lib\\site-packages (from tqdm->proglog<=1.0.0->moviepy) (0.4.6)\n",
            "Downloading moviepy-2.2.1-py3-none-any.whl (129 kB)\n",
            "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl (31.2 MB)\n",
            "   ---------------------------------------- 0.0/31.2 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.8/31.2 MB 4.2 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 1.6/31.2 MB 4.4 MB/s eta 0:00:07\n",
            "   --- ------------------------------------ 2.4/31.2 MB 3.8 MB/s eta 0:00:08\n",
            "   ---- ----------------------------------- 3.1/31.2 MB 4.1 MB/s eta 0:00:07\n",
            "   ----- ---------------------------------- 4.2/31.2 MB 4.1 MB/s eta 0:00:07\n",
            "   ------ --------------------------------- 5.0/31.2 MB 4.2 MB/s eta 0:00:07\n",
            "   ------- -------------------------------- 5.8/31.2 MB 4.1 MB/s eta 0:00:07\n",
            "   -------- ------------------------------- 6.8/31.2 MB 4.1 MB/s eta 0:00:06\n",
            "   --------- ------------------------------ 7.6/31.2 MB 4.2 MB/s eta 0:00:06\n",
            "   ---------- ----------------------------- 8.4/31.2 MB 4.1 MB/s eta 0:00:06\n",
            "   ------------ --------------------------- 9.4/31.2 MB 4.2 MB/s eta 0:00:06\n",
            "   ------------- -------------------------- 10.2/31.2 MB 4.2 MB/s eta 0:00:06\n",
            "   -------------- ------------------------- 11.0/31.2 MB 4.2 MB/s eta 0:00:05\n",
            "   --------------- ------------------------ 12.1/31.2 MB 4.2 MB/s eta 0:00:05\n",
            "   ---------------- ----------------------- 13.1/31.2 MB 4.3 MB/s eta 0:00:05\n",
            "   ------------------ --------------------- 14.2/31.2 MB 4.3 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 15.2/31.2 MB 4.4 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 16.0/31.2 MB 4.4 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 17.0/31.2 MB 4.4 MB/s eta 0:00:04\n",
            "   ----------------------- ---------------- 18.1/31.2 MB 4.4 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 19.1/31.2 MB 4.4 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 20.2/31.2 MB 4.5 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 21.0/31.2 MB 4.5 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 22.0/31.2 MB 4.5 MB/s eta 0:00:03\n",
            "   ----------------------------- ---------- 23.3/31.2 MB 4.5 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 24.4/31.2 MB 4.6 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 25.4/31.2 MB 4.6 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 26.5/31.2 MB 4.6 MB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 27.5/31.2 MB 4.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 28.8/31.2 MB 4.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 29.9/31.2 MB 4.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  30.9/31.2 MB 4.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 31.2/31.2 MB 4.7 MB/s eta 0:00:00\n",
            "Downloading proglog-0.1.12-py3-none-any.whl (6.3 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, imageio_ffmpeg, imageio, proglog, moviepy\n",
            "Successfully installed imageio-2.37.0 imageio_ffmpeg-0.6.0 moviepy-2.2.1 proglog-0.1.12 python-dotenv-1.1.0\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:dlEnv]",
      "name": "conda-env-dlEnv-py",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}