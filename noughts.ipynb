{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import copy"
      ],
      "metadata": {
        "id": "HJQMQHvxf8uM"
      },
      "id": "HJQMQHvxf8uM",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class checkBoard:\n",
        "    board = [[0, 0, 0],[0, 0, 0],[0, 0, 0]]\n",
        "    available_places = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "    def check_winner(self, player):\n",
        "    # Check rows, columns and diagonals\n",
        "        for i in range(3):\n",
        "            if all([cell == player for cell in self.board[i]]) or \\\n",
        "            all([self.board[j][i] == player for j in range(3)]):\n",
        "                return True\n",
        "        if all([self.board[i][i] == player for i in range(3)]) or \\\n",
        "        all([self.board[i][2 - i] == player for i in range(3)]):\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def game_end_state(self):\n",
        "        winner_one = self.check_winner(1)\n",
        "        winner_two = self.check_winner(2)\n",
        "        no_available_spaces = (len(self.available_places) == 0)\n",
        "        game_state = {}\n",
        "        game_state[\"winner\"] = 1 if winner_one else 2 if winner_two else 0\n",
        "        game_state[\"game_over\"] = no_available_spaces or winner_one or winner_two\n",
        "        game_state[\"tie\"] = no_available_spaces and not winner_one and not winner_two\n",
        "        game_state[\"reward_player_two\"] = -1 if winner_one else 1 if winner_two else 0\n",
        "        return game_state\n",
        "\n",
        "    def reset_board(self):\n",
        "        self.board = [[0, 0, 0],[0, 0, 0],[0, 0, 0]]\n",
        "        self.available_places = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "    def board_state(self): # Added self to access instance variables\n",
        "        return self.board, self.available_places\n",
        "\n",
        "    def print_board(self):\n",
        "        for row in self.board:\n",
        "            print(\" | \".join(\"\".join(map(str, row)).replace(\"0\",\" \").replace(\"2\",\"X\").replace(\"1\",\"O\")))\n",
        "            print(\"-\" * 5)\n",
        "\n",
        "    def move(self, move, current_player = 1):\n",
        "        if not 1 <= int(move) <= 9:\n",
        "            print(\"Invalid input. Please enter a number between 1 and 9.\")\n",
        "            return False\n",
        "\n",
        "        move = int(move) - 1\n",
        "        row, col = divmod(move, 3)\n",
        "\n",
        "        if self.board[row][col] > 0:\n",
        "            print(\"That spot is already taken. Try again.\")\n",
        "            return False\n",
        "        else:\n",
        "            self.board[row][col] = current_player\n",
        "            self.available_places.remove(move + 1)\n",
        "            return True\n",
        "\n",
        "    def move_random(self, current_player ):\n",
        "        if not self.available_places:\n",
        "            return None\n",
        "        move_place = random.choice(self.available_places)\n",
        "        self.move(move_place, current_player)\n",
        "        return move_place\n",
        "\n",
        "def ext_print_board(self):\n",
        "    for row in self.board:\n",
        "        print(\" | \".join(\"\".join(map(str, row)).replace(\"0\",\" \").replace(\"2\",\"X\").replace(\"1\",\"O\")))\n",
        "        print(\"-\" * 5)"
      ],
      "metadata": {
        "id": "-eqxNByrqNE2"
      },
      "id": "-eqxNByrqNE2",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ACTIONS = 9\n",
        "STATE_SIZE = 9\n",
        "EMPTY = 0\n",
        "PLAYER = 1\n",
        "OPPONENT = -1\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "EPSILON = 0.1\n",
        "ALPHA = 0.001\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000"
      ],
      "metadata": {
        "id": "_guQRxWTl3J3"
      },
      "id": "_guQRxWTl3J3",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action(state, model, epsilon=EPSILON):\n",
        "    valid_actions = [i for i in range(NUM_ACTIONS) if state[i] == EMPTY]\n",
        "    if np.random.rand() < epsilon:\n",
        "        return random.choice(valid_actions)\n",
        "\n",
        "    q_values = model.predict(state[np.newaxis], verbose=0)[0]\n",
        "    masked_q = np.full(NUM_ACTIONS, -np.inf)\n",
        "    for a in valid_actions:\n",
        "        masked_q[a] = q_values[a]\n",
        "    return np.argmax(masked_q)"
      ],
      "metadata": {
        "id": "EM8M0MAvhduB"
      },
      "id": "EM8M0MAvhduB",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_dqn_model(input_shape=(9,), num_actions=9):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_actions, activation='linear')  # Q-values for each action\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "IAkrptH2YXjT"
      },
      "id": "IAkrptH2YXjT",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dqn(model, memory, target_model):\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "\n",
        "    batch = random.sample(memory, BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones = zip(*batch)\n",
        "    targets = model.predict(states, verbose=0)\n",
        "    next_q = target_model.predict(next_states, verbose=0)\n",
        "\n",
        "    for i in range(BATCH_SIZE):\n",
        "        if dones[i]:\n",
        "            targets[i][actions[i]] = rewards[i]\n",
        "        else:\n",
        "            valid_next_actions = [a for a in range(NUM_ACTIONS) if next_states[i][a] == EMPTY]\n",
        "            max_future_q = max(next_q[i][a] for a in valid_next_actions)\n",
        "            targets[i][actions[i]] = rewards[i] + GAMMA * max_future_q\n",
        "\n",
        "    model.fit(states, targets, epochs=1, verbose=0)"
      ],
      "metadata": {
        "id": "FJLckDilxnVl"
      },
      "id": "FJLckDilxnVl",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remember(memory, state, action, reward, next_state, done):\n",
        "    memory.append((np.array(state).reshape(1, -1), action, reward, np.array(next_state).reshape(1, -1), done))\n",
        "\n",
        "def create_data():\n",
        "    MEMORY_SIZE = 10000\n",
        "    memory = deque(maxlen=MEMORY_SIZE)\n",
        "    SAMPLE_NUM = 100\n",
        "\n",
        "    for i in range(SAMPLE_NUM):\n",
        "        checkBoardGame = checkBoard()\n",
        "        checkBoardGame.reset_board()\n",
        "        game_state = checkBoardGame.game_end_state()\n",
        "        turn = True\n",
        "\n",
        "        while not(game_state[\"game_over\"]):\n",
        "            last_checkBoardState = copy.deepcopy(checkBoardGame.board_state()[0])\n",
        "            turn = not(turn)\n",
        "            move_made = None\n",
        "            if(turn):\n",
        "                move_made = checkBoardGame.move_random(2)\n",
        "            else:\n",
        "                checkBoardGame.move_random(1)\n",
        "            game_state = checkBoardGame.game_end_state()\n",
        "            if(move_made != None):\n",
        "                remember(memory, last_checkBoardState, move_made, game_state[\"reward_player_two\"], copy.deepcopy(checkBoardGame.board_state()[0]), game_state[\"game_over\"])\n",
        "\n",
        "    # checkBoardGame.print_board()\n",
        "    # print(game_state[\"winner\"])\n",
        "    return memory"
      ],
      "metadata": {
        "id": "Rqn8TJaIweox"
      },
      "id": "Rqn8TJaIweox",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "73p60yzMA8SA"
      },
      "id": "73p60yzMA8SA"
    },
    {
      "cell_type": "code",
      "source": [
        "dqn_model = create_dqn_model()\n",
        "memory = create_data()"
      ],
      "metadata": {
        "id": "oQTRL-aR96LX"
      },
      "id": "oQTRL-aR96LX",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dqn(dqn_model, memory, _)"
      ],
      "metadata": {
        "id": "dz8XQj7jA7jB",
        "outputId": "93200567-793b-4898-b140-aff5a69b2578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "id": "dz8XQj7jA7jB",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: keras_tensor_12\n",
            "Received: inputs=('Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))', 'Tensor(shape=(1, 9))')\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3d3ff157a02c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-cd5fbb4de426>\u001b[0m in \u001b[0;36mtrain_dqn\u001b[0;34m(model, memory, target_model)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mvalid_next_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_ACTIONS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEMPTY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mmax_future_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_next_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_future_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-cd5fbb4de426>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mvalid_next_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_ACTIONS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEMPTY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mmax_future_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_next_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_future_q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ArAbPWANBDCI"
      },
      "id": "ArAbPWANBDCI",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}