{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import copy\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "HJQMQHvxf8uM"
      },
      "id": "HJQMQHvxf8uM",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class checkBoard:\n",
        "    board = np.zeros(9)\n",
        "    available_places = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "    def reset_board(self):\n",
        "        self.board = np.zeros(9)\n",
        "        self.available_places = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
        "\n",
        "    def board_state(self):\n",
        "        return np.array(self.board).reshape(1, -1)\n",
        "\n",
        "    def check_winner(self, board):\n",
        "        wins = [\n",
        "            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rows\n",
        "            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # columns\n",
        "            [0, 4, 8], [2, 4, 6]              # diagonals\n",
        "        ]\n",
        "        for a, b, c in wins:\n",
        "            if self.board[a] == self.board[b] == self.board[c] and self.board[a] in (1, 2):\n",
        "                return board[a]\n",
        "        return None\n",
        "\n",
        "    def game_end_state(self):\n",
        "        no_available_spaces = (len(self.available_places) == 0)\n",
        "        game_state = {}\n",
        "\n",
        "        game_state[\"winner\"] = self.check_winner(self.board)\n",
        "        game_state[\"game_over\"] = no_available_spaces or game_state[\"winner\"]\n",
        "        return game_state\n",
        "\n",
        "    def print_board(self):\n",
        "        print(\"\\n\")\n",
        "        for i in range(0, 9, 3):\n",
        "            row = self.board[i:i+3]\n",
        "            print(' | '.join({1:\"O\", 2:\"X\"}[cell] if cell in (1, 2) else ' ' for cell in row))\n",
        "            if i < 6:\n",
        "                print('---------')\n",
        "\n",
        "\n",
        "    def move(self, move, current_player = \"X\"):\n",
        "        if move not in self.available_places:\n",
        "            print(\"Invalid move. Try again.\")\n",
        "            return False\n",
        "        else:\n",
        "            self.board[move] = current_player\n",
        "            self.available_places.remove(move)\n",
        "            return True\n",
        "\n",
        "    def move_random(self, current_player = \"O\"):\n",
        "        if not self.available_places:\n",
        "            return None\n",
        "        move_place = random.choice(self.available_places)\n",
        "        self.move(move_place, current_player)\n",
        "        return move_place"
      ],
      "metadata": {
        "id": "-eqxNByrqNE2"
      },
      "id": "-eqxNByrqNE2",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkBoardX = checkBoard()\n",
        "\n",
        "wins = {1:0,2:0,None:0}\n",
        "for i in tqdm(range(100)):\n",
        "    checkBoardX.reset_board()\n",
        "    turn = random.choice([True, False])\n",
        "    game_state = checkBoardX.game_end_state()\n",
        "    while not(game_state[\"game_over\"]):\n",
        "        turn = not(turn)\n",
        "        if(turn):\n",
        "            # print(checkBoardX.available_places)\n",
        "            # move = choose_action(dqn_model, checkBoardX, 0)\n",
        "            # print(move)\n",
        "            # checkBoardX.move(move, 2)\n",
        "            checkBoardX.move_random(2)\n",
        "        else:\n",
        "            checkBoardX.move_random(1)\n",
        "        game_state = checkBoardX.game_end_state()\n",
        "    wins[game_state[\"winner\"]]+=1\n",
        "print(wins)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC4WCUCCS5_G",
        "outputId": "baec1992-4056-4944-9959-1a69f9229eea"
      },
      "id": "PC4WCUCCS5_G",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:00<00:00, 12058.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 48, 2: 41, None: 11}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ACTIONS = 9\n",
        "STATE_SIZE = 9\n",
        "EMPTY = 0\n",
        "PLAYER = 2\n",
        "OPPONENT = 1\n",
        "\n",
        "# Hyperparameters\n",
        "GAMMA = 0.99\n",
        "EPSILON = 0.1\n",
        "ALPHA = 0.001\n",
        "BATCH_SIZE = 32\n",
        "MEMORY_SIZE = 10000"
      ],
      "metadata": {
        "id": "_guQRxWTl3J3"
      },
      "id": "_guQRxWTl3J3",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dqn_model(input_shape=(9,), num_actions=9):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_actions, activation='linear')  # Q-values for each action\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='mse')\n",
        "    return model"
      ],
      "metadata": {
        "id": "IAkrptH2YXjT"
      },
      "id": "IAkrptH2YXjT",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remember(memory, state, action, reward, next_state, done):\n",
        "    memory.append((np.array(state).reshape(1, -1), action, reward, np.array(next_state).reshape(1, -1), done))\n",
        "\n",
        "def create_data(MEMORY_SIZE):\n",
        "    memory = deque(maxlen=MEMORY_SIZE)\n",
        "    for i in range(MEMORY_SIZE):\n",
        "        checkBoardGame = checkBoard()\n",
        "        checkBoardGame.reset_board()\n",
        "        game_state = checkBoardGame.game_end_state()\n",
        "        turn = True\n",
        "\n",
        "        while not(game_state[\"game_over\"]):\n",
        "            last_checkBoardState = copy.deepcopy(checkBoardGame.board_state()[0])\n",
        "            turn = not(turn)\n",
        "            move_made = None\n",
        "            if(turn):\n",
        "                move_made = checkBoardGame.move_random(2)\n",
        "            else:\n",
        "                checkBoardGame.move_random(1)\n",
        "            game_state = checkBoardGame.game_end_state()\n",
        "            if(move_made != None):\n",
        "                remember(memory, last_checkBoardState, move_made, game_state[\"reward_player_two\"], copy.deepcopy(checkBoardGame.board_state()[0]), game_state[\"game_over\"])\n",
        "\n",
        "    # checkBoardGame.print_board()\n",
        "    # print(game_state[\"winner\"])\n",
        "    return memory"
      ],
      "metadata": {
        "id": "Rqn8TJaIweox"
      },
      "id": "Rqn8TJaIweox",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dqn(model, memory, target_model):\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "\n",
        "    batch = random.sample(memory, BATCH_SIZE)\n",
        "    states, actions, rewards, next_states, dones = zip(*batch)\n",
        "\n",
        "    states = np.array(states).reshape(BATCH_SIZE, -1)\n",
        "    next_states = np.array(next_states).reshape(BATCH_SIZE, -1)\n",
        "\n",
        "    targets = model.predict(states, verbose=0)\n",
        "    next_q = target_model.predict(next_states, verbose=0)\n",
        "\n",
        "    for i in range(BATCH_SIZE):\n",
        "        if dones[i]:\n",
        "            targets[i][actions[i]] = rewards[i] #Subtract 1 from actions[i] since it's using 1-based indexing\n",
        "        else:\n",
        "            valid_next_actions = [a for a in range(NUM_ACTIONS) if next_states[i][a] == EMPTY]\n",
        "            #Subtract 1 from the values in valid_next_actions\n",
        "            valid_next_actions = [a for a in valid_next_actions]\n",
        "            #Check if valid_next_actions is empty\n",
        "            if not valid_next_actions:\n",
        "                max_future_q = 0 # or any default value if there are no valid actions\n",
        "            else:\n",
        "                max_future_q = max(next_q[i][a] for a in valid_next_actions)\n",
        "            targets[i][actions[i]] = rewards[i] + GAMMA * max_future_q #Subtract 1 from actions[i]\n",
        "\n",
        "    model.fit(states, targets, epochs=1, verbose=0)"
      ],
      "metadata": {
        "id": "FJLckDilxnVl"
      },
      "id": "FJLckDilxnVl",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_action(model, board, epsilon=EPSILON):\n",
        "    if np.random.rand() < epsilon:\n",
        "        return random.choice(board.available_places)\n",
        "\n",
        "    q_values = model.predict(board.board_state(), verbose=0)[0]\n",
        "    masked_q = np.full(NUM_ACTIONS, -np.inf)\n",
        "    for a in board.available_places:\n",
        "        masked_q[a] = q_values[a]\n",
        "    return np.argmax(masked_q)"
      ],
      "metadata": {
        "id": "EM8M0MAvhduB"
      },
      "id": "EM8M0MAvhduB",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "73p60yzMA8SA"
      },
      "id": "73p60yzMA8SA"
    },
    {
      "cell_type": "code",
      "source": [
        "dqn_model = create_dqn_model()\n",
        "target_model = create_dqn_model()\n",
        "memory = create_data(MEMORY_SIZE)\n",
        "\n",
        "for i in tqdm(range(100)):\n",
        "    train_dqn(dqn_model, memory, target_model)\n",
        "    target_model.set_weights(dqn_model.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQTRL-aR96LX",
        "outputId": "aa6db3e3-2fb0-4973-dfe0-c2b83e1490b4"
      },
      "id": "oQTRL-aR96LX",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:37<00:00,  2.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkBoardX = checkBoard()\n",
        "\n",
        "wins = [0,0,0]\n",
        "pbar = tqdm(range(1000))\n",
        "\n",
        "for i in pbar:\n",
        "    checkBoardX.reset_board()\n",
        "    turn = random.choice([True, False])\n",
        "    game_state = checkBoardX.game_end_state()\n",
        "    while not(game_state[\"game_over\"]):\n",
        "        turn = not(turn)\n",
        "        if(turn):\n",
        "            # print(checkBoardX.available_places)\n",
        "            move = choose_action(dqn_model, checkBoardX, 0)\n",
        "            # print(move)\n",
        "            checkBoardX.move(move, 2)\n",
        "            # checkBoardX.move_random(2)\n",
        "        else:\n",
        "            checkBoardX.move_random(1)\n",
        "        game_state = checkBoardX.game_end_state()\n",
        "    wins[game_state[\"winner\"]] += 1\n",
        "    pbar.set_postfix({'wins': wins})\n",
        "print(\"\\nPlayer 1 :\" , wins[1])\n",
        "print(\"Player 2 :\" , wins[2])\n",
        "print(\"Tie :\" , wins[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odvc1kdYU_uV",
        "outputId": "0f57e68c-5910-4258-a33c-5d1f33116c2f"
      },
      "id": "Odvc1kdYU_uV",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [09:02<00:00,  1.84it/s, wins=[285, 381, 334]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Player 1 : 381\n",
            "Player 2 : 334\n",
            "Tie : 285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}